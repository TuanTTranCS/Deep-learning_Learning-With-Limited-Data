{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Hugo_Testbest_challenge1_RandomSearch",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "614bad4a89dc400297e36d5a9ff6b24a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_84f6216df50949f79338869a3e228d78",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_6f6678b5140147c1b9b1cd44c34f9d97",
              "IPY_MODEL_0b61a9d6b92c42b3941aa1d439939669"
            ]
          }
        },
        "84f6216df50949f79338869a3e228d78": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6f6678b5140147c1b9b1cd44c34f9d97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_1f6710080ce6448480d3f7244f381433",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 170498071,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 170498071,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_94d5f200c48b4989b8c97dfd2a89fa88"
          }
        },
        "0b61a9d6b92c42b3941aa1d439939669": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_35c469bb6eab44b6a69a95c9964e00ad",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 170499072/? [00:14&lt;00:00, 11518346.51it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_75bcad6eefa945b4abe8681aaac77864"
          }
        },
        "1f6710080ce6448480d3f7244f381433": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "94d5f200c48b4989b8c97dfd2a89fa88": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "35c469bb6eab44b6a69a95c9964e00ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "75bcad6eefa945b4abe8681aaac77864": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vV6DxGkPeQDD"
      },
      "source": [
        "***Challenge 1***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "72hfgxjTd_lk"
      },
      "source": [
        "Here the goal is to train on 100 samples. In this preliminary testbed the evaluation will be done on a 2000 sample validation set. Note in the end the final evaluation will be done on the full CIFAR-10 test set as well as potentially a separate dataset. The validation samples here should not be used for training in any way, the final evaluation will provide only random samples of 100 from a datasource that is not the CIFAR-10 training data. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zk0Ilt_-duk2"
      },
      "source": [
        "Feel free to modify this testbed to your liking, including the normalization transformations etc. Note however the final evaluation testbed will have a rigid set of components where you will need to place your answer. The only constraint is the data. Refer to the full project instructions for more information.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bt4RKss-MKWM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88929d61-ebcc-4f5a-ffcf-4df686d3d711"
      },
      "source": [
        "import os\n",
        "output_path = 'output_txt/'\n",
        "img_path = 'img/'\n",
        "Colab = False\n",
        "Kaggle = 'kaggle' in os.getcwd()\n",
        "root = '.' # Root to download dataset\n",
        "if 'google.colab' in str(get_ipython()):\n",
        "    print('Running on CoLab')\n",
        "    Colab = True  \n",
        "    from google.colab import drive\n",
        "    if not os.path.exists('/content/drive/MyDrive/'):\n",
        "        drive.mount('/content/drive', force_remount=False)\n",
        "    else:\n",
        "        print('Drive already mounted at at /content/drive')\n",
        "    Google_path = '/content/drive/MyDrive/Colab Notebooks/COMP691_project/'\n",
        "    if not os.path.exists(Google_path):\n",
        "        os.mkdir(Google_path)\n",
        "    img_path = Google_path + img_path\n",
        "    if not os.path.exists(img_path):\n",
        "        os.mkdir(img_path)\n",
        "    output_path = Google_path + output_path  \n",
        "else:\n",
        "    if Kaggle:\n",
        "        root = '../input/cifar10'\n",
        "        output_path = ''\n",
        "        img_path = ''\n",
        "        print('Running in Kaggle')\n",
        "    else:\n",
        "        print('Not running on CoLab or Kaggle')\n",
        "output_file_name = 'report_ADAM_cosine_improve_ResNet9_RandomSearch_new.txt'\n",
        "output_file_path = output_path + output_file_name\n",
        "progress_file = output_path + 'Random_search_ResNet9_progress_new.txt'\n",
        "img_file_name_prefix = output_file_name.replace('.txt', '')\n",
        "img_file_path = img_path + img_file_name_prefix + '/'\n",
        "save_state_file_path = output_file_path.replace('.txt', '.pkl')\n",
        "if not os.path.exists(img_file_path):\n",
        "    os.mkdir(img_file_path)\n",
        "if not os.path.exists(output_path):\n",
        "    os.mkdir(output_path)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running on CoLab\n",
            "Drive already mounted at at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MWyBTUe3idZI"
      },
      "source": [
        "Setup training functions. Again you are free to fully modify this testbed in your prototyping within the constraints of the data used. You can use tools outside of pytorch for training models if desired as well although the torchvision dataloaders will still be useful for interacting with the cifar-10 dataset. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N7soYNWEedl9"
      },
      "source": [
        "import gc\n",
        "import math\n",
        "from matplotlib import pyplot as plt \n",
        "from numpy import unravel_index\n",
        "\n",
        "def train(model, device, train_loader, optimizer, epoch, grad_clip=None, sched=None, display=True):\n",
        "    model.train()\n",
        "    loss_function = nn.CosineEmbeddingLoss()\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data).to(device)\n",
        "\n",
        "        GT=torch.zeros((len(target),10))\n",
        "        for idx in range(len(target)):\n",
        "            GT[idx][target[idx]]=1\n",
        "\n",
        "        GT=GT.to(device)\n",
        "        \n",
        "        loss = loss_function(output, GT, torch.Tensor(output.size(0)).to(device).fill_(1.0))\n",
        "        #loss = F.cross_entropy(output, target)\n",
        "        loss.backward()\n",
        "        if grad_clip:\n",
        "            nn.utils.clip_grad_value_(model.parameters(), grad_clip)\n",
        "        optimizer.step()\n",
        "        if sched:\n",
        "            sched.step()\n",
        "        if display and (batch_idx == 0 or batch_idx + 1 == len(train_loader)):\n",
        "          print('   Train Epoch: {} [step {}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "              epoch + 1, batch_idx + 1, len(train_loader),\n",
        "              100. * batch_idx / len(train_loader), loss.detach().item()))\n",
        "        if device == torch.device('cuda'):\n",
        "            del loss, output\n",
        "            gc.collect()\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "def test(model, device, test_loader, display=True):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    loss_function = nn.CosineEmbeddingLoss()\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            GT=torch.zeros((len(target),10))\n",
        "            for idx in range(len(target)):\n",
        "                GT[idx][target[idx]]=1\n",
        "\n",
        "            GT=GT.to(device)\n",
        "            \n",
        "            test_loss += loss_function(output, GT, torch.Tensor(output.size(0)).to(device).fill_(1.0)).item() # sum up batch loss\n",
        "            #test_loss += F.cross_entropy(output, target, size_average=False).item()\n",
        "            pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    if display:\n",
        "        print('   Test set: Average loss: {:.6f}, Accuracy: {}/{} ({:.2f}%)'.format(\n",
        "            test_loss, correct, len(test_loader.dataset),\n",
        "            100. * correct / len(test_loader.dataset)))\n",
        "    return 100. * correct / len(test_loader.dataset)\n",
        "\n",
        "def plot_accs(accs_accross_runs, display_str, comment='N/A', save_img=True):\n",
        "    plt.figure();\n",
        "    #epochs = list(range(1, len(accs_accross_runs[0]) + 1))\n",
        "    max_acc_display = ''\n",
        "    for i, run_accs in enumerate(accs_accross_runs):\n",
        "        max_acc = max(run_accs)\n",
        "        max_epochs = [index + 1 for index, acc in enumerate(run_accs) if acc == max_acc]\n",
        "        max_acc_display = f' - max acc: {max_acc}% at epochs {max_epochs}'\n",
        "        plt.plot(run_accs, label=f'Run #{i + 1}' + max_acc_display)\n",
        "    plt.xlabel('epochs')\n",
        "    plt.ylabel('Test accuracy (%)')\n",
        "    plt.legend();\n",
        "    plt.title(f'Test accuracies for \\n{display_str}Note: {comment}');\n",
        "\n",
        "    if save_img:\n",
        "        scenario = display_str[display_str.index(' ') + 1: display_str.index('/')].replace(' ','')\n",
        "        img_name = img_file_path + f'{scenario}' + generate_image_suffix()\n",
        "        #print(img_name)\n",
        "        plt.savefig(img_name, bbox_inches='tight')\n",
        "\n",
        "def generate_image_suffix():\n",
        "    return f'_{time.time()%10000000:.0f}' + '.png'\n",
        "\n",
        "def performance_summary(accumulated_accs):\n",
        "    scenarios = len(accumulated_accs)\n",
        "    str_output = f'\\nCurrent performance summary over {scenarios} completed scenario(s): '\n",
        "    top_20_percent_count = math.ceil(scenarios/10) # Top k performances\n",
        "    k = top_20_percent_count\n",
        "    top_20_final_accs = [(1, 0, 0) for _ in range(1, k + 1)] # (scenario, final acc means, std)\n",
        "    top_20_max_accs = [(1, 0, 0, 0) for _ in range(1, k + 1)] # (scenario, run, epoch, max_acc)\n",
        "    top_20_least_variant = [(1, 0, 999) for _ in range(1, k + 1)] # (scenario, final acc means, std)\n",
        "    for scenario, scenario_accs in enumerate(accumulated_accs):\n",
        "        \n",
        "        scenario_accs = np.array(scenario_accs)\n",
        "        run_final_accs_mean, run_final_acc_std = scenario_accs[:, -1].mean(), scenario_accs[:, -1].std()\n",
        "        #print(f'scen {scenario} - acc {run_final_accs_mean:.3f} - std {run_final_acc_std:.3f}')\n",
        "        idx = np.argpartition(scenario_accs, -k, axis=None)\n",
        "        top_k_scenario_max_indices = [unravel_index(i, scenario_accs.shape) for i in np.sort(idx[-k:])]\n",
        "        #print(top_k_scenario_max_indices)\n",
        "        for run, epoch in top_k_scenario_max_indices:\n",
        "            #print(run, epoch)\n",
        "            top_scenario_max_acc = scenario_accs[run, epoch]\n",
        "            top_20_max_accs.append((scenario, run, epoch, top_scenario_max_acc))\n",
        "        #print(top_20_max_accs)\n",
        "        if k < len(top_20_max_accs):\n",
        "            global_max_accs = [top_scenario_max_acc for (_, _, _, top_scenario_max_acc) in top_20_max_accs]\n",
        "            idx = np.argpartition(global_max_accs, -k, axis=None)\n",
        "            top_20_max_accs = [top_20_max_accs[i] for i in sorted(idx[-k:].tolist(), reverse=True)]\n",
        "        #for i, (max_scen, max_acc_mean, max_acc_std) in enumerate(top_20_final_accs):\n",
        "        top_20_final_accs.append((scenario, run_final_accs_mean, run_final_acc_std))\n",
        "        if k < len(top_20_final_accs):\n",
        "            global_final_accs = [run_final_accs_mean for (_, run_final_accs_mean, _) in top_20_final_accs]\n",
        "            idx = np.argpartition(global_final_accs, -k, axis=None)\n",
        "            top_20_final_accs = [top_20_final_accs[i]  for i in sorted(idx[-k:].tolist(), reverse=True)]\n",
        "        top_20_least_variant.append((scenario, run_final_accs_mean, run_final_acc_std))\n",
        "        #print(top_20_least_variant)\n",
        "        if k < len(top_20_least_variant):\n",
        "            global_final_stds = [run_final_acc_std for (_, _, run_final_acc_std) in top_20_least_variant]\n",
        "            #print(global_final_stds)\n",
        "            idx = np.argpartition(global_final_stds, k, axis=None)\n",
        "            #print(idx)\n",
        "            top_20_least_variant = [top_20_least_variant[i] for i in sorted(idx[:k].tolist())]\n",
        "    str_output += f'\\n - Top {k} final average accuracy:'\n",
        "    for (scenario, run_final_accs_mean, run_final_acc_std) in top_20_final_accs:\n",
        "        str_output += f'\\n   + Scenario: {scenario + 1} - Final average accuracy: {run_final_accs_mean:.2f} +- {run_final_acc_std:.2f}%'\n",
        "    str_output += f'\\n - Top {k} max accuracy:'\n",
        "    for (scenario, run, epoch, top_scenario_max_acc) in top_20_max_accs:\n",
        "        str_output += f'\\n   + Scenario: {scenario + 1} - run {run + 1} - epoch {epoch + 1} - Max accuracy: {top_scenario_max_acc:.2f}'\n",
        "    str_output += f'\\n - Top {k} least final accuracy variation:'\n",
        "    for (scenario, run_final_accs_mean, run_final_acc_std) in top_20_least_variant:\n",
        "        str_output += f'\\n   + Scenario: {scenario + 1} - Final average accuracy: {run_final_accs_mean:.2f} +- {run_final_acc_std:.2f}%'\n",
        "    return str_output"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G4hpe7QbQFnr"
      },
      "source": [
        "import torch.nn as nn \n",
        "import torch.nn.functional as F\n",
        "num_classes = 10\n",
        "in_channels = 3\n",
        "\n",
        "def conv_block(in_channels, out_channels, drop_out=0, pool=False):\n",
        "    layers = [nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1), \n",
        "              nn.BatchNorm2d(out_channels), \n",
        "              nn.ReLU(inplace=True), nn.Dropout(drop_out)\n",
        "              ]\n",
        "    if pool: layers.append(nn.MaxPool2d(2))\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "class NET(nn.Module):\n",
        "    def __init__(self, in_channels, num_classes, drop_out):\n",
        "#         super().__init__()\n",
        "#         # Use a pretrained model\n",
        "#         self.network = models.resnet34(pretrained=True)\n",
        "#         # Replace last layer\n",
        "#         num_ftrs = self.network.fc.in_features\n",
        "#         self.network.fc = nn.Linear(num_ftrs, num_classes)\n",
        "        super().__init__()\n",
        "        \n",
        "        self.conv1 = conv_block(in_channels, 64, drop_out)\n",
        "        self.conv2 = conv_block(64, 128, drop_out, pool=True)\n",
        "        self.res1 = nn.Sequential(conv_block(128, 128, drop_out), conv_block(128, 128, drop_out))\n",
        "        self.dropout = nn.Dropout(drop_out)\n",
        "        self.conv3 = conv_block(128, 256, drop_out, pool=True)\n",
        "        self.conv4 = conv_block(256, 512, drop_out, pool=True)\n",
        "        self.res2 = nn.Sequential(conv_block(512, 512, drop_out), conv_block(512, 512, drop_out))\n",
        "        self.conv5 = conv_block(512, 1028, drop_out, pool=True)\n",
        "        self.res3 = nn.Sequential(conv_block(1028, 1028, drop_out), conv_block(1028, 1028, drop_out))\n",
        "        \n",
        "        self.classifier = nn.Sequential(nn.MaxPool2d(2), \n",
        "                                        nn.Flatten(), \n",
        "                                        nn.Linear(1028, num_classes))\n",
        "        \n",
        "    \n",
        "#     def forward(self, xb):\n",
        "        \n",
        "#         return torch.relu(self.network(xb))\n",
        "    def forward(self, xb):\n",
        "        out = self.conv1(xb)\n",
        "        out = self.conv2(out)\n",
        "        out = self.res1(out) + out\n",
        "        out = self.conv3(out)\n",
        "        out = self.dropout(out)\n",
        "        out = self.conv4(out)\n",
        "        out = self.dropout(out)\n",
        "        out = self.res2(out) + out\n",
        "        out = self.conv5(out)\n",
        "        out = self.res3(out) + out\n",
        "        out = self.classifier(out)\n",
        "        return out\n",
        "\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jPjWBE4MerTX"
      },
      "source": [
        "The below tries  2 random problem instances. In your development you may choose to prototype with 1 problem instances but keep in mind for small sample problems the variance is high so continously evaluating on several subsets will be important."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6v7xU1HMelJ3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "614bad4a89dc400297e36d5a9ff6b24a",
            "84f6216df50949f79338869a3e228d78",
            "6f6678b5140147c1b9b1cd44c34f9d97",
            "0b61a9d6b92c42b3941aa1d439939669",
            "1f6710080ce6448480d3f7244f381433",
            "94d5f200c48b4989b8c97dfd2a89fa88",
            "35c469bb6eab44b6a69a95c9964e00ad",
            "75bcad6eefa945b4abe8681aaac77864"
          ]
        },
        "outputId": "15864cd8-c4fa-4844-8ff2-8fe3167c801e"
      },
      "source": [
        "#%%time\n",
        "import time\n",
        "import pickle\n",
        "from scipy.stats import loguniform\n",
        "from numpy.random import RandomState\n",
        "import torchvision\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Subset\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "\n",
        "search_plot = True\n",
        "log_enabled = True\n",
        "save_image = True\n",
        "summarize = True\n",
        "comment = 'ResNet9 + Adam optim + Data Augmentation + Random search'\n",
        "save_state = {}\n",
        "\n",
        "if summarize:\n",
        "    if not log_enabled:\n",
        "        raise NameError('log_enabled should be True in order to enable summarize!')\n",
        "    if os.path.exists(save_state_file_path):\n",
        "        with open(save_state_file_path ,'rb') as dataHandle:\n",
        "            save_state = pickle.load(dataHandle)\n",
        "accumulated_accs = []\n",
        "# Epochs: 300 - lr: - 0.001 - dropout: 0 - Weight_decay: 1e-05 - Grad_clip: 0.005 \n",
        "#epochs_list = [200, 500, 800, 1000]\n",
        "if len(save_state) == 0:\n",
        "    epochs_list = [700]\n",
        "    save_state['epochs'] =  epochs_list\n",
        "    #grad_clips = [0.005, 0.01, 0.1, 1]\n",
        "    grad_clips = sorted(list(loguniform(1e-4, 1).rvs(5, random_state=0)))\n",
        "    save_state['grad_clips'] = grad_clips\n",
        "    #weight_decays = [1e-3, 1e-4, 1e-5]\n",
        "    weight_decays = sorted(list(loguniform(1e-5, 1e-3).rvs(5, random_state=0)))\n",
        "    save_state['weight_decays'] = weight_decays\n",
        "    lrs = [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05]\n",
        "    save_state['lrs'] = lrs\n",
        "    #lrs = [0.01, 0.005, 1e-3, 1e-4]\n",
        "    #drop_outs = [0, 0.1, 0.2]\n",
        "    drop_outs = [0, 0.1]\n",
        "    save_state['drop_outs'] = drop_outs\n",
        "    if summarize:\n",
        "        with open(save_state_file_path, 'wb') as dataHandle:\n",
        "            pickle.dump(save_state, dataHandle)\n",
        "    \n",
        "    print(f'First time run on profile {output_file_name}') \n",
        "else:\n",
        "    epochs_list = save_state['epochs']\n",
        "    grad_clips = save_state['grad_clips']\n",
        "    weight_decays = save_state['weight_decays']\n",
        "    lrs = save_state['lrs']\n",
        "    drop_outs = save_state['drop_outs']\n",
        "    accumulated_accs = save_state['accs']\n",
        "    print(f'Successfully loaded save state from profile {output_file_name}') \n",
        "\n",
        "batch_size = 128\n",
        "runs = 5\n",
        "epoch_display_range = 100\n",
        "\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "#device = torch.device('cpu')\n",
        "device_name = torch.cuda.get_device_name(0) if device == torch.device('cuda') else 'cpu'\n",
        "scenario_count = len(epochs_list) * len(weight_decays) * len(lrs) * len(drop_outs) * len(grad_clips)\n",
        "print(f'Total scenarios: {scenario_count}')\n",
        "for key, value in save_state.items():\n",
        "    if key != 'accs':\n",
        "        print(f'{key}: {value}')  \n",
        "\n",
        "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                  std=[0.229, 0.224, 0.225])\n",
        "\n",
        "transform_train = transforms.Compose([\n",
        "                                    transforms.RandomCrop(32, padding=4, padding_mode='reflect'),\n",
        "                                    transforms.RandomGrayscale(),\n",
        "                                    transforms.RandomHorizontalFlip(),\n",
        "                                    torchvision.transforms.RandomAffine(degrees=30),\n",
        "                                    transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.2), \n",
        "                                    #transforms.ColorJitter(), \n",
        "                                    transforms.ToTensor(), \n",
        "                                    normalize]) #careful to keep this one same\n",
        "transform_val = transforms.Compose([transforms.ToTensor(), normalize]) \n",
        "\n",
        "\n",
        "print('Running on {}'.format(device_name))\n",
        "\n",
        "##### Cifar Data\n",
        "cifar_data = datasets.CIFAR10(root='.',train=True, transform=transform_train, download=True)\n",
        "    \n",
        "#We need two copies of this due to weird dataset api \n",
        "cifar_data_val = datasets.CIFAR10(root='.',train=True, transform=transform_val, download=True)\n",
        "\n",
        "\n",
        "# Extract a subset of 100 (class balanced) samples per class\n",
        "training_done = False\n",
        "count = 1\n",
        "scenario = 1\n",
        "next_run = 1\n",
        "previous_runs_accs = []\n",
        "previous_train_times = []\n",
        "previous_eval_times = []\n",
        "previous_exec_times = []\n",
        "\n",
        "ran_in_middle = False\n",
        "\n",
        "if log_enabled:\n",
        "    if os.path.exists(progress_file):\n",
        "        with open(progress_file, 'r') as file_read:\n",
        "            progress_content = file_read.readlines()\n",
        "        # print(progress_content)\n",
        "        if progress_content[0].replace('\\n', '') == output_file_name:\n",
        "            previous_scenario = progress_content[1].replace('\\n', '')\n",
        "            previous_runs_accs = eval(progress_content[2].replace('\\n', ''))\n",
        "            previous_runs = len(previous_runs_accs)\n",
        "            print(f'Previous progress on {output_file_name} stopped at scenario {previous_scenario}/{scenario_count}' +\\\n",
        "                 f', run {previous_runs}/{runs}')\n",
        "            if previous_runs >= runs: # Already complete the previous scenario\n",
        "                scenario = int(previous_scenario) + 1\n",
        "\n",
        "            else: # Previous scenario just completed partially, resume in the next run\n",
        "                ran_in_middle = True\n",
        "                scenario = int(previous_scenario)\n",
        "                next_run = previous_runs + 1\n",
        "                previous_execution_times = eval(progress_content[3].replace('\\n', ''))\n",
        "                prev_accs_accross_runs_plot = eval(progress_content[4].replace('\\n', ''))\n",
        "                for i, previous_execution_time in enumerate(previous_execution_times):\n",
        "                    previous_train_times.append(previous_execution_time[0]) \n",
        "                    previous_eval_times.append(previous_execution_time[1]) \n",
        "                    previous_exec_times.append(previous_execution_time[2])  \n",
        "            if scenario > scenario_count:\n",
        "                training_done = True\n",
        "                print('Training was already done!')\n",
        "            else:\n",
        "                print(f'Will resume training at scenario: {scenario}, run# {next_run}')\n",
        "\n",
        "\n",
        "if not training_done:\n",
        "    for epochs in epochs_list:\n",
        "        for lr in lrs:\n",
        "            for drop_out in drop_outs:\n",
        "                for weight_decay in weight_decays:\n",
        "                    for grad_clip in grad_clips:\n",
        "\n",
        "                        if not ran_in_middle: \n",
        "\n",
        "                            accs = []\n",
        "                            train_times = []\n",
        "                            evaluation_times = []\n",
        "                            total_times = []\n",
        "                            run_execution_times = []\n",
        "                            accs_accross_runs_plot = []\n",
        "                        else:\n",
        "                            if count < scenario:\n",
        "                                count += 1\n",
        "                                continue #skip until reaching the scenario to run\n",
        "                            accs = previous_runs_accs\n",
        "                            train_times = previous_train_times\n",
        "                            evaluation_times = previous_eval_times\n",
        "                            total_times = previous_exec_times\n",
        "                            run_execution_times = previous_execution_times\n",
        "                            accs_accross_runs_plot = prev_accs_accross_runs_plot\n",
        "                        #scenario += 1\n",
        "                        scenario_description = 'Scenario %d/%d - Epochs: %d - lr: - %s - dropout: %s - Weight_decay: %s - Grad_clip: %s'%\\\n",
        "                        (scenario, scenario_count, epochs, lr, drop_out, weight_decay, grad_clip)\n",
        "                        print('\\n' + scenario_description)\n",
        "                        \n",
        "                        for seed in range(next_run, runs + 1):\n",
        "                            start_time = time.time()\n",
        "\n",
        "                            prng = RandomState(seed)\n",
        "                            random_permute = prng.permutation(np.arange(0, 5000))\n",
        "                            indx_train = np.concatenate([np.where(np.array(cifar_data.targets) == classe)[0][random_permute[0:10]] for classe in range(0, 10)])\n",
        "                            indx_val = np.concatenate([np.where(np.array(cifar_data_val.targets) == classe)[0][random_permute[10:210]] for classe in range(0, 10)])\n",
        "\n",
        "\n",
        "                            train_data = Subset(cifar_data, indx_train)\n",
        "                            val_data = Subset(cifar_data_val, indx_val)\n",
        "\n",
        "                            print('  Run# [%d/%d] - Num Samples For Training %d - Num Samples For Val %d'%(seed, runs, train_data.indices.shape[0],val_data.indices.shape[0]))\n",
        "\n",
        "                            train_loader = torch.utils.data.DataLoader(train_data,\n",
        "                                                                        batch_size=batch_size, \n",
        "                                                                        shuffle=True)\n",
        "\n",
        "                            val_loader = torch.utils.data.DataLoader(val_data,\n",
        "                                                                    batch_size=batch_size, \n",
        "                                                                    shuffle=False)\n",
        "\n",
        "                            model = NET(in_channels, num_classes, drop_out)\n",
        "                            model.to(device)\n",
        "                            optimizer = torch.optim.Adam(model.parameters(), \n",
        "                                                        lr=lr, \n",
        "                                                        #momentum=0.9,\n",
        "                                                        weight_decay=weight_decay)\n",
        "                            sched = torch.optim.lr_scheduler.OneCycleLR(optimizer, lr, epochs=epochs, \n",
        "                                                                            steps_per_epoch=len(train_loader))\n",
        "                            test_accs = []\n",
        "                            eval_time = 0\n",
        "                            for epoch in range(epochs):\n",
        "                                print_condition = epoch%epoch_display_range==0 or epoch==epochs-1\n",
        "                                train(model, device, train_loader, optimizer, epoch, grad_clip=grad_clip,\n",
        "                                    sched=sched, display=print_condition)\n",
        "                                if search_plot:\n",
        "                                    eval_start = time.time()\n",
        "                                    test_acc = test(model, device, val_loader, display=print_condition)\n",
        "                                    eval_time = time.time() - eval_start\n",
        "                                    test_accs.append(test_acc)\n",
        "\n",
        "                                    \n",
        "                            train_time = time.time() - start_time    \n",
        "                            train_times.append(train_time)\n",
        "                            final_eval_start = time.time()\n",
        "                            final_acc = test_accs[-1] if search_plot else test(model, device, val_loader)\n",
        "                            accs.append(final_acc)\n",
        "                            final_eval_time = eval_time if search_plot else time.time() - final_eval_start\n",
        "                            evaluation_times.append(final_eval_time)\n",
        "                            if search_plot:\n",
        "                                accs_accross_runs_plot.append(test_accs)\n",
        "                            total_time = time.time() - start_time\n",
        "                            total_times.append(total_time)\n",
        "                            run_execution_times.append((train_time, final_eval_time, total_time))\n",
        "                            if log_enabled:\n",
        "                                progress_str = f'{output_file_name}\\n{scenario}\\n{accs}\\n{run_execution_times}' +\\\n",
        "                                f'\\n{accs_accross_runs_plot}'\n",
        "\n",
        "                                with open(progress_file, 'w') as progress_write:\n",
        "                                    progress_write.write(progress_str)\n",
        "                            if device == torch.device('cuda'):\n",
        "                                del optimizer\n",
        "                                gc.collect()\n",
        "                                torch.cuda.empty_cache()\n",
        "                            print('  Run execution time: train: %.3f (s) - eval: %.3f (s)- total: %.3f (s)'%\\\n",
        "                                  (train_time, final_eval_time, total_time))\n",
        "                        accs = np.array(accs)\n",
        "                        train_times = np.array(train_times)\n",
        "                        evaluation_times = np.array(evaluation_times)\n",
        "                        total_times = np.array(total_times)\n",
        "                        \n",
        "                        accuracy_description = '\\n  Final acc over %d instances: %.2f +- %.2f\\n'%(runs, accs.mean(), accs.std())\n",
        "                        # print(train_times.mean(), evaluation_times.mean(), total_times.mean())\n",
        "                        display_str = '  %s'%(scenario_description) +\\\n",
        "                        '\\n  Train time %.3f +- %.3f (s) - eval time %.3f +- %.3f (s) - total: %.3f +- %.3f (s) on %s'%\\\n",
        "                        (train_times.mean(), train_times.std(), evaluation_times.mean(), evaluation_times.std(),\n",
        "                             total_times.mean(), total_times.std(), device_name) + accuracy_description\n",
        "                        accumulated_accs.append(accs_accross_runs_plot)\n",
        "                        #progress_str = f'{output_file_name}\\n{scenario}\\n{accs}'\n",
        "                        print(display_str)\n",
        "                        if search_plot:\n",
        "                            plot_str = display_str # scenario_description + accuracy_description\n",
        "                            plot_accs(accs_accross_runs_plot, plot_str, comment, save_image)\n",
        "                        if summarize:\n",
        "                            save_state['accs'] = accumulated_accs\n",
        "                            with open(save_state_file_path, 'wb') as dataHandle:\n",
        "                                pickle.dump(save_state, dataHandle)\n",
        "                            summary = performance_summary(accumulated_accs)\n",
        "                            print(summary)\n",
        "                            display_str += summary\n",
        "                        \n",
        "                        if log_enabled:\n",
        "                            mode = 'a' if os.path.exists(output_file_path) else 'w'\n",
        "\n",
        "                            with open(output_file_path, mode) as output_write:\n",
        "                                output_write.write('\\n' + display_str)\n",
        "                        ran_in_middle = False\n",
        "                        next_run = 1\n",
        "                        scenario += 1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Successfully loaded save state from profile report_ADAM_cosine_improve_ResNet9_RandomSearch_new.txt\n",
            "Total scenarios: 300\n",
            "epochs: [700]\n",
            "grad_clips: [0.004950159553733192, 0.015119336467640998, 0.01567667719550606, 0.02576638574613588, 0.07257005721594274]\n",
            "weight_decays: [7.035737028722145e-05, 0.00012296071107325705, 0.0001252065381499946, 0.00016051911333587627, 0.000269388301928541]\n",
            "lrs: [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05]\n",
            "drop_outs: [0, 0.1]\n",
            "Running on Tesla P100-PCIE-16GB\n",
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "614bad4a89dc400297e36d5a9ff6b24a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=170498071.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Extracting ./cifar-10-python.tar.gz to .\n",
            "Files already downloaded and verified\n",
            "Previous progress on report_ADAM_cosine_improve_ResNet9_RandomSearch_new.txt stopped at scenario 84/300, run 3/5\n",
            "Will resume training at scenario: 84, run# 4\n",
            "\n",
            "Scenario 84/300 - Epochs: 700 - lr: - 0.0005 - dropout: 0.1 - Weight_decay: 0.00012296071107325705 - Grad_clip: 0.02576638574613588\n",
            "  Run# [4/5] - Num Samples For Training 100 - Num Samples For Val 2000\n",
            "   Train Epoch: 1 [step 1/1 (0%)]\tLoss: 0.945983\n",
            "   Test set: Average loss: 0.007183, Accuracy: 204/2000 (10.20%)\n",
            "   Train Epoch: 101 [step 1/1 (0%)]\tLoss: 0.410179\n",
            "   Test set: Average loss: 0.004804, Accuracy: 565/2000 (28.25%)\n",
            "   Train Epoch: 201 [step 1/1 (0%)]\tLoss: 0.127061\n",
            "   Test set: Average loss: 0.004721, Accuracy: 647/2000 (32.35%)\n",
            "   Train Epoch: 301 [step 1/1 (0%)]\tLoss: 0.048112\n",
            "   Test set: Average loss: 0.004954, Accuracy: 687/2000 (34.35%)\n",
            "   Train Epoch: 401 [step 1/1 (0%)]\tLoss: 0.018753\n",
            "   Test set: Average loss: 0.004904, Accuracy: 664/2000 (33.20%)\n",
            "   Train Epoch: 501 [step 1/1 (0%)]\tLoss: 0.013367\n",
            "   Test set: Average loss: 0.004944, Accuracy: 678/2000 (33.90%)\n",
            "   Train Epoch: 601 [step 1/1 (0%)]\tLoss: 0.003530\n",
            "   Test set: Average loss: 0.004546, Accuracy: 762/2000 (38.10%)\n",
            "   Train Epoch: 700 [step 1/1 (0%)]\tLoss: 0.002511\n",
            "   Test set: Average loss: 0.004553, Accuracy: 759/2000 (37.95%)\n",
            "  Run execution time: train: 827.166 (s) - eval: 0.937 (s)- total: 827.166 (s)\n",
            "  Run# [5/5] - Num Samples For Training 100 - Num Samples For Val 2000\n",
            "   Train Epoch: 1 [step 1/1 (0%)]\tLoss: 1.182207\n",
            "   Test set: Average loss: 0.008046, Accuracy: 200/2000 (10.00%)\n",
            "   Train Epoch: 101 [step 1/1 (0%)]\tLoss: 0.430531\n",
            "   Test set: Average loss: 0.004926, Accuracy: 595/2000 (29.75%)\n",
            "   Train Epoch: 201 [step 1/1 (0%)]\tLoss: 0.159473\n",
            "   Test set: Average loss: 0.004702, Accuracy: 765/2000 (38.25%)\n",
            "   Train Epoch: 301 [step 1/1 (0%)]\tLoss: 0.055927\n",
            "   Test set: Average loss: 0.004812, Accuracy: 706/2000 (35.30%)\n",
            "   Train Epoch: 401 [step 1/1 (0%)]\tLoss: 0.025071\n",
            "   Test set: Average loss: 0.004484, Accuracy: 780/2000 (39.00%)\n",
            "   Train Epoch: 501 [step 1/1 (0%)]\tLoss: 0.011824\n",
            "   Test set: Average loss: 0.004527, Accuracy: 766/2000 (38.30%)\n",
            "   Train Epoch: 601 [step 1/1 (0%)]\tLoss: 0.003389\n",
            "   Test set: Average loss: 0.004462, Accuracy: 795/2000 (39.75%)\n",
            "   Train Epoch: 700 [step 1/1 (0%)]\tLoss: 0.002414\n",
            "   Test set: Average loss: 0.004419, Accuracy: 796/2000 (39.80%)\n",
            "  Run execution time: train: 806.449 (s) - eval: 0.889 (s)- total: 806.449 (s)\n",
            "  Scenario 84/300 - Epochs: 700 - lr: - 0.0005 - dropout: 0.1 - Weight_decay: 0.00012296071107325705 - Grad_clip: 0.02576638574613588\n",
            "  Train time 823.165 +- 8.419 (s) - eval time 0.921 +- 0.018 (s) - total: 823.165 +- 8.419 (s) on Tesla P100-PCIE-16GB\n",
            "  Final acc over 5 instances: 38.62 +- 0.88\n",
            "\n",
            "\n",
            "Current performance summary over 84 completed scenario(s): \n",
            " - Top 9 final average accuracy:\n",
            "   + Scenario: 74 - Final average accuracy: 39.14 +- 1.58%\n",
            "   + Scenario: 72 - Final average accuracy: 39.06 +- 1.26%\n",
            "   + Scenario: 60 - Final average accuracy: 39.23 +- 1.38%\n",
            "   + Scenario: 56 - Final average accuracy: 38.98 +- 1.43%\n",
            "   + Scenario: 54 - Final average accuracy: 39.06 +- 1.74%\n",
            "   + Scenario: 51 - Final average accuracy: 39.31 +- 0.91%\n",
            "   + Scenario: 55 - Final average accuracy: 39.06 +- 0.91%\n",
            "   + Scenario: 59 - Final average accuracy: 38.97 +- 1.24%\n",
            "   + Scenario: 69 - Final average accuracy: 39.35 +- 1.48%\n",
            " - Top 9 max accuracy:\n",
            "   + Scenario: 70 - run 1 - epoch 487 - Max accuracy: 41.65\n",
            "   + Scenario: 23 - run 6 - epoch 457 - Max accuracy: 41.75\n",
            "   + Scenario: 23 - run 6 - epoch 459 - Max accuracy: 41.65\n",
            "   + Scenario: 23 - run 6 - epoch 476 - Max accuracy: 41.75\n",
            "   + Scenario: 23 - run 6 - epoch 477 - Max accuracy: 41.85\n",
            "   + Scenario: 23 - run 6 - epoch 478 - Max accuracy: 41.60\n",
            "   + Scenario: 23 - run 6 - epoch 479 - Max accuracy: 41.85\n",
            "   + Scenario: 55 - run 6 - epoch 516 - Max accuracy: 41.70\n",
            "   + Scenario: 57 - run 4 - epoch 670 - Max accuracy: 41.60\n",
            " - Top 9 least final accuracy variation:\n",
            "   + Scenario: 2 - Final average accuracy: 38.41 +- 0.73%\n",
            "   + Scenario: 17 - Final average accuracy: 38.74 +- 0.67%\n",
            "   + Scenario: 19 - Final average accuracy: 38.33 +- 0.50%\n",
            "   + Scenario: 25 - Final average accuracy: 38.60 +- 0.77%\n",
            "   + Scenario: 34 - Final average accuracy: 35.09 +- 0.69%\n",
            "   + Scenario: 62 - Final average accuracy: 38.93 +- 0.83%\n",
            "   + Scenario: 68 - Final average accuracy: 38.49 +- 0.75%\n",
            "   + Scenario: 76 - Final average accuracy: 38.69 +- 0.73%\n",
            "   + Scenario: 78 - Final average accuracy: 38.63 +- 0.73%\n",
            "\n",
            "Scenario 85/300 - Epochs: 700 - lr: - 0.0005 - dropout: 0.1 - Weight_decay: 0.00012296071107325705 - Grad_clip: 0.07257005721594274\n",
            "  Run# [1/5] - Num Samples For Training 100 - Num Samples For Val 2000\n",
            "   Train Epoch: 1 [step 1/1 (0%)]\tLoss: 0.941186\n",
            "   Test set: Average loss: 0.007486, Accuracy: 200/2000 (10.00%)\n",
            "   Train Epoch: 101 [step 1/1 (0%)]\tLoss: 0.363714\n",
            "   Test set: Average loss: 0.004955, Accuracy: 603/2000 (30.15%)\n",
            "   Train Epoch: 201 [step 1/1 (0%)]\tLoss: 0.121906\n",
            "   Test set: Average loss: 0.004949, Accuracy: 683/2000 (34.15%)\n",
            "   Train Epoch: 301 [step 1/1 (0%)]\tLoss: 0.045190\n",
            "   Test set: Average loss: 0.004812, Accuracy: 678/2000 (33.90%)\n",
            "   Train Epoch: 401 [step 1/1 (0%)]\tLoss: 0.011747\n",
            "   Test set: Average loss: 0.004951, Accuracy: 648/2000 (32.40%)\n",
            "   Train Epoch: 501 [step 1/1 (0%)]\tLoss: 0.013542\n",
            "   Test set: Average loss: 0.004756, Accuracy: 725/2000 (36.25%)\n",
            "   Train Epoch: 601 [step 1/1 (0%)]\tLoss: 0.004298\n",
            "   Test set: Average loss: 0.004704, Accuracy: 750/2000 (37.50%)\n",
            "   Train Epoch: 700 [step 1/1 (0%)]\tLoss: 0.005774\n",
            "   Test set: Average loss: 0.004646, Accuracy: 753/2000 (37.65%)\n",
            "  Run execution time: train: 804.808 (s) - eval: 0.903 (s)- total: 804.808 (s)\n",
            "  Run# [2/5] - Num Samples For Training 100 - Num Samples For Val 2000\n",
            "   Train Epoch: 1 [step 1/1 (0%)]\tLoss: 1.085594\n",
            "   Test set: Average loss: 0.008965, Accuracy: 217/2000 (10.85%)\n",
            "   Train Epoch: 101 [step 1/1 (0%)]\tLoss: 0.404055\n",
            "   Test set: Average loss: 0.005463, Accuracy: 482/2000 (24.10%)\n",
            "   Train Epoch: 201 [step 1/1 (0%)]\tLoss: 0.158559\n",
            "   Test set: Average loss: 0.005036, Accuracy: 641/2000 (32.05%)\n",
            "   Train Epoch: 301 [step 1/1 (0%)]\tLoss: 0.045703\n",
            "   Test set: Average loss: 0.004953, Accuracy: 702/2000 (35.10%)\n",
            "   Train Epoch: 401 [step 1/1 (0%)]\tLoss: 0.021738\n",
            "   Test set: Average loss: 0.005139, Accuracy: 659/2000 (32.95%)\n",
            "   Train Epoch: 501 [step 1/1 (0%)]\tLoss: 0.005325\n",
            "   Test set: Average loss: 0.004666, Accuracy: 748/2000 (37.40%)\n",
            "   Train Epoch: 601 [step 1/1 (0%)]\tLoss: 0.003192\n",
            "   Test set: Average loss: 0.004804, Accuracy: 711/2000 (35.55%)\n",
            "   Train Epoch: 700 [step 1/1 (0%)]\tLoss: 0.005623\n",
            "   Test set: Average loss: 0.004764, Accuracy: 733/2000 (36.65%)\n",
            "  Run execution time: train: 805.756 (s) - eval: 0.912 (s)- total: 805.756 (s)\n",
            "  Run# [3/5] - Num Samples For Training 100 - Num Samples For Val 2000\n",
            "   Train Epoch: 1 [step 1/1 (0%)]\tLoss: 0.919739\n",
            "   Test set: Average loss: 0.007747, Accuracy: 172/2000 (8.60%)\n",
            "   Train Epoch: 101 [step 1/1 (0%)]\tLoss: 0.414935\n",
            "   Test set: Average loss: 0.005200, Accuracy: 578/2000 (28.90%)\n",
            "   Train Epoch: 201 [step 1/1 (0%)]\tLoss: 0.141839\n",
            "   Test set: Average loss: 0.004781, Accuracy: 639/2000 (31.95%)\n",
            "   Train Epoch: 301 [step 1/1 (0%)]\tLoss: 0.033453\n",
            "   Test set: Average loss: 0.004781, Accuracy: 676/2000 (33.80%)\n",
            "   Train Epoch: 401 [step 1/1 (0%)]\tLoss: 0.024421\n",
            "   Test set: Average loss: 0.004894, Accuracy: 676/2000 (33.80%)\n",
            "   Train Epoch: 501 [step 1/1 (0%)]\tLoss: 0.005169\n",
            "   Test set: Average loss: 0.004901, Accuracy: 673/2000 (33.65%)\n",
            "   Train Epoch: 601 [step 1/1 (0%)]\tLoss: 0.003731\n",
            "   Test set: Average loss: 0.004826, Accuracy: 678/2000 (33.90%)\n",
            "   Train Epoch: 700 [step 1/1 (0%)]\tLoss: 0.003400\n",
            "   Test set: Average loss: 0.004858, Accuracy: 669/2000 (33.45%)\n",
            "  Run execution time: train: 808.098 (s) - eval: 0.908 (s)- total: 808.098 (s)\n",
            "  Run# [4/5] - Num Samples For Training 100 - Num Samples For Val 2000\n",
            "   Train Epoch: 1 [step 1/1 (0%)]\tLoss: 1.104247\n",
            "   Test set: Average loss: 0.008050, Accuracy: 200/2000 (10.00%)\n",
            "   Train Epoch: 101 [step 1/1 (0%)]\tLoss: 0.403454\n",
            "   Test set: Average loss: 0.004802, Accuracy: 594/2000 (29.70%)\n",
            "   Train Epoch: 201 [step 1/1 (0%)]\tLoss: 0.149061\n",
            "   Test set: Average loss: 0.004916, Accuracy: 680/2000 (34.00%)\n",
            "   Train Epoch: 301 [step 1/1 (0%)]\tLoss: 0.054580\n",
            "   Test set: Average loss: 0.004896, Accuracy: 655/2000 (32.75%)\n",
            "   Train Epoch: 401 [step 1/1 (0%)]\tLoss: 0.021165\n",
            "   Test set: Average loss: 0.004975, Accuracy: 693/2000 (34.65%)\n",
            "   Train Epoch: 501 [step 1/1 (0%)]\tLoss: 0.003721\n",
            "   Test set: Average loss: 0.004704, Accuracy: 728/2000 (36.40%)\n",
            "   Train Epoch: 601 [step 1/1 (0%)]\tLoss: 0.005520\n",
            "   Test set: Average loss: 0.004764, Accuracy: 681/2000 (34.05%)\n",
            "   Train Epoch: 700 [step 1/1 (0%)]\tLoss: 0.008329\n",
            "   Test set: Average loss: 0.004718, Accuracy: 716/2000 (35.80%)\n",
            "  Run execution time: train: 801.404 (s) - eval: 0.887 (s)- total: 801.404 (s)\n",
            "  Run# [5/5] - Num Samples For Training 100 - Num Samples For Val 2000\n",
            "   Train Epoch: 1 [step 1/1 (0%)]\tLoss: 0.965366\n",
            "   Test set: Average loss: 0.007503, Accuracy: 234/2000 (11.70%)\n",
            "   Train Epoch: 101 [step 1/1 (0%)]\tLoss: 0.386744\n",
            "   Test set: Average loss: 0.004860, Accuracy: 595/2000 (29.75%)\n",
            "   Train Epoch: 201 [step 1/1 (0%)]\tLoss: 0.123900\n",
            "   Test set: Average loss: 0.004911, Accuracy: 687/2000 (34.35%)\n",
            "   Train Epoch: 301 [step 1/1 (0%)]\tLoss: 0.051169\n",
            "   Test set: Average loss: 0.004935, Accuracy: 671/2000 (33.55%)\n",
            "   Train Epoch: 401 [step 1/1 (0%)]\tLoss: 0.020430\n",
            "   Test set: Average loss: 0.004619, Accuracy: 736/2000 (36.80%)\n",
            "   Train Epoch: 501 [step 1/1 (0%)]\tLoss: 0.019861\n",
            "   Test set: Average loss: 0.004739, Accuracy: 722/2000 (36.10%)\n",
            "   Train Epoch: 601 [step 1/1 (0%)]\tLoss: 0.008604\n",
            "   Test set: Average loss: 0.004634, Accuracy: 747/2000 (37.35%)\n",
            "   Train Epoch: 700 [step 1/1 (0%)]\tLoss: 0.003574\n",
            "   Test set: Average loss: 0.004548, Accuracy: 760/2000 (38.00%)\n",
            "  Run execution time: train: 804.861 (s) - eval: 0.898 (s)- total: 804.861 (s)\n",
            "  Scenario 85/300 - Epochs: 700 - lr: - 0.0005 - dropout: 0.1 - Weight_decay: 0.00012296071107325705 - Grad_clip: 0.07257005721594274\n",
            "  Train time 804.985 +- 2.152 (s) - eval time 0.902 +- 0.009 (s) - total: 804.985 +- 2.152 (s) on Tesla P100-PCIE-16GB\n",
            "  Final acc over 5 instances: 36.31 +- 1.63\n",
            "\n",
            "\n",
            "Current performance summary over 85 completed scenario(s): \n",
            " - Top 9 final average accuracy:\n",
            "   + Scenario: 69 - Final average accuracy: 39.35 +- 1.48%\n",
            "   + Scenario: 59 - Final average accuracy: 38.97 +- 1.24%\n",
            "   + Scenario: 55 - Final average accuracy: 39.06 +- 0.91%\n",
            "   + Scenario: 51 - Final average accuracy: 39.31 +- 0.91%\n",
            "   + Scenario: 54 - Final average accuracy: 39.06 +- 1.74%\n",
            "   + Scenario: 56 - Final average accuracy: 38.98 +- 1.43%\n",
            "   + Scenario: 60 - Final average accuracy: 39.23 +- 1.38%\n",
            "   + Scenario: 72 - Final average accuracy: 39.06 +- 1.26%\n",
            "   + Scenario: 74 - Final average accuracy: 39.14 +- 1.58%\n",
            " - Top 9 max accuracy:\n",
            "   + Scenario: 57 - run 4 - epoch 670 - Max accuracy: 41.60\n",
            "   + Scenario: 55 - run 6 - epoch 516 - Max accuracy: 41.70\n",
            "   + Scenario: 23 - run 6 - epoch 479 - Max accuracy: 41.85\n",
            "   + Scenario: 23 - run 6 - epoch 478 - Max accuracy: 41.60\n",
            "   + Scenario: 23 - run 6 - epoch 477 - Max accuracy: 41.85\n",
            "   + Scenario: 23 - run 6 - epoch 476 - Max accuracy: 41.75\n",
            "   + Scenario: 23 - run 6 - epoch 459 - Max accuracy: 41.65\n",
            "   + Scenario: 23 - run 6 - epoch 457 - Max accuracy: 41.75\n",
            "   + Scenario: 70 - run 1 - epoch 487 - Max accuracy: 41.65\n",
            " - Top 9 least final accuracy variation:\n",
            "   + Scenario: 2 - Final average accuracy: 38.41 +- 0.73%\n",
            "   + Scenario: 17 - Final average accuracy: 38.74 +- 0.67%\n",
            "   + Scenario: 19 - Final average accuracy: 38.33 +- 0.50%\n",
            "   + Scenario: 25 - Final average accuracy: 38.60 +- 0.77%\n",
            "   + Scenario: 34 - Final average accuracy: 35.09 +- 0.69%\n",
            "   + Scenario: 62 - Final average accuracy: 38.93 +- 0.83%\n",
            "   + Scenario: 68 - Final average accuracy: 38.49 +- 0.75%\n",
            "   + Scenario: 76 - Final average accuracy: 38.69 +- 0.73%\n",
            "   + Scenario: 78 - Final average accuracy: 38.63 +- 0.73%\n",
            "\n",
            "Scenario 86/300 - Epochs: 700 - lr: - 0.0005 - dropout: 0.1 - Weight_decay: 0.0001252065381499946 - Grad_clip: 0.004950159553733192\n",
            "  Run# [1/5] - Num Samples For Training 100 - Num Samples For Val 2000\n",
            "   Train Epoch: 1 [step 1/1 (0%)]\tLoss: 1.032420\n",
            "   Test set: Average loss: 0.009393, Accuracy: 200/2000 (10.00%)\n",
            "   Train Epoch: 101 [step 1/1 (0%)]\tLoss: 0.389475\n",
            "   Test set: Average loss: 0.004991, Accuracy: 607/2000 (30.35%)\n",
            "   Train Epoch: 201 [step 1/1 (0%)]\tLoss: 0.123259\n",
            "   Test set: Average loss: 0.004944, Accuracy: 667/2000 (33.35%)\n",
            "   Train Epoch: 301 [step 1/1 (0%)]\tLoss: 0.063444\n",
            "   Test set: Average loss: 0.004845, Accuracy: 694/2000 (34.70%)\n",
            "   Train Epoch: 401 [step 1/1 (0%)]\tLoss: 0.034839\n",
            "   Test set: Average loss: 0.005025, Accuracy: 644/2000 (32.20%)\n",
            "   Train Epoch: 501 [step 1/1 (0%)]\tLoss: 0.011707\n",
            "   Test set: Average loss: 0.004761, Accuracy: 726/2000 (36.30%)\n",
            "   Train Epoch: 601 [step 1/1 (0%)]\tLoss: 0.003472\n",
            "   Test set: Average loss: 0.004513, Accuracy: 769/2000 (38.45%)\n",
            "   Train Epoch: 700 [step 1/1 (0%)]\tLoss: 0.002447\n",
            "   Test set: Average loss: 0.004553, Accuracy: 776/2000 (38.80%)\n",
            "  Run execution time: train: 800.855 (s) - eval: 0.901 (s)- total: 800.855 (s)\n",
            "  Run# [2/5] - Num Samples For Training 100 - Num Samples For Val 2000\n",
            "   Train Epoch: 1 [step 1/1 (0%)]\tLoss: 1.117454\n",
            "   Test set: Average loss: 0.009603, Accuracy: 200/2000 (10.00%)\n",
            "   Train Epoch: 101 [step 1/1 (0%)]\tLoss: 0.406829\n",
            "   Test set: Average loss: 0.005512, Accuracy: 481/2000 (24.05%)\n",
            "   Train Epoch: 201 [step 1/1 (0%)]\tLoss: 0.131233\n",
            "   Test set: Average loss: 0.005145, Accuracy: 649/2000 (32.45%)\n",
            "   Train Epoch: 301 [step 1/1 (0%)]\tLoss: 0.050343\n",
            "   Test set: Average loss: 0.005150, Accuracy: 622/2000 (31.10%)\n",
            "   Train Epoch: 401 [step 1/1 (0%)]\tLoss: 0.028268\n",
            "   Test set: Average loss: 0.004663, Accuracy: 757/2000 (37.85%)\n",
            "   Train Epoch: 501 [step 1/1 (0%)]\tLoss: 0.008751\n",
            "   Test set: Average loss: 0.004688, Accuracy: 755/2000 (37.75%)\n",
            "   Train Epoch: 601 [step 1/1 (0%)]\tLoss: 0.002542\n",
            "   Test set: Average loss: 0.004699, Accuracy: 743/2000 (37.15%)\n",
            "   Train Epoch: 700 [step 1/1 (0%)]\tLoss: 0.003930\n",
            "   Test set: Average loss: 0.004665, Accuracy: 754/2000 (37.70%)\n",
            "  Run execution time: train: 806.921 (s) - eval: 0.920 (s)- total: 806.921 (s)\n",
            "  Run# [3/5] - Num Samples For Training 100 - Num Samples For Val 2000\n",
            "   Train Epoch: 1 [step 1/1 (0%)]\tLoss: 0.885845\n",
            "   Test set: Average loss: 0.007674, Accuracy: 257/2000 (12.85%)\n",
            "   Train Epoch: 101 [step 1/1 (0%)]\tLoss: 0.388281\n",
            "   Test set: Average loss: 0.005091, Accuracy: 591/2000 (29.55%)\n",
            "   Train Epoch: 201 [step 1/1 (0%)]\tLoss: 0.152685\n",
            "   Test set: Average loss: 0.004947, Accuracy: 670/2000 (33.50%)\n",
            "   Train Epoch: 301 [step 1/1 (0%)]\tLoss: 0.041218\n",
            "   Test set: Average loss: 0.004779, Accuracy: 674/2000 (33.70%)\n",
            "   Train Epoch: 401 [step 1/1 (0%)]\tLoss: 0.044395\n",
            "   Test set: Average loss: 0.004706, Accuracy: 710/2000 (35.50%)\n",
            "   Train Epoch: 501 [step 1/1 (0%)]\tLoss: 0.005588\n",
            "   Test set: Average loss: 0.004847, Accuracy: 689/2000 (34.45%)\n",
            "   Train Epoch: 601 [step 1/1 (0%)]\tLoss: 0.002391\n",
            "   Test set: Average loss: 0.004627, Accuracy: 734/2000 (36.70%)\n",
            "   Train Epoch: 700 [step 1/1 (0%)]\tLoss: 0.004133\n",
            "   Test set: Average loss: 0.004653, Accuracy: 727/2000 (36.35%)\n",
            "  Run execution time: train: 803.475 (s) - eval: 0.904 (s)- total: 803.475 (s)\n",
            "  Run# [4/5] - Num Samples For Training 100 - Num Samples For Val 2000\n",
            "   Train Epoch: 1 [step 1/1 (0%)]\tLoss: 0.929401\n",
            "   Test set: Average loss: 0.007910, Accuracy: 210/2000 (10.50%)\n",
            "   Train Epoch: 101 [step 1/1 (0%)]\tLoss: 0.423242\n",
            "   Test set: Average loss: 0.004790, Accuracy: 612/2000 (30.60%)\n",
            "   Train Epoch: 201 [step 1/1 (0%)]\tLoss: 0.109579\n",
            "   Test set: Average loss: 0.004806, Accuracy: 724/2000 (36.20%)\n",
            "   Train Epoch: 301 [step 1/1 (0%)]\tLoss: 0.035310\n",
            "   Test set: Average loss: 0.004846, Accuracy: 701/2000 (35.05%)\n",
            "   Train Epoch: 401 [step 1/1 (0%)]\tLoss: 0.011377\n",
            "   Test set: Average loss: 0.004826, Accuracy: 696/2000 (34.80%)\n",
            "   Train Epoch: 501 [step 1/1 (0%)]\tLoss: 0.013918\n",
            "   Test set: Average loss: 0.004751, Accuracy: 715/2000 (35.75%)\n",
            "   Train Epoch: 601 [step 1/1 (0%)]\tLoss: 0.002063\n",
            "   Test set: Average loss: 0.004630, Accuracy: 736/2000 (36.80%)\n",
            "   Train Epoch: 700 [step 1/1 (0%)]\tLoss: 0.003268\n",
            "   Test set: Average loss: 0.004643, Accuracy: 737/2000 (36.85%)\n",
            "  Run execution time: train: 806.335 (s) - eval: 0.899 (s)- total: 806.335 (s)\n",
            "  Run# [5/5] - Num Samples For Training 100 - Num Samples For Val 2000\n",
            "   Train Epoch: 1 [step 1/1 (0%)]\tLoss: 0.915402\n",
            "   Test set: Average loss: 0.008006, Accuracy: 200/2000 (10.00%)\n",
            "   Train Epoch: 101 [step 1/1 (0%)]\tLoss: 0.405811\n",
            "   Test set: Average loss: 0.004857, Accuracy: 578/2000 (28.90%)\n",
            "   Train Epoch: 201 [step 1/1 (0%)]\tLoss: 0.131477\n",
            "   Test set: Average loss: 0.004514, Accuracy: 737/2000 (36.85%)\n",
            "   Train Epoch: 301 [step 1/1 (0%)]\tLoss: 0.058565\n",
            "   Test set: Average loss: 0.004465, Accuracy: 765/2000 (38.25%)\n",
            "   Train Epoch: 401 [step 1/1 (0%)]\tLoss: 0.024873\n",
            "   Test set: Average loss: 0.004667, Accuracy: 736/2000 (36.80%)\n",
            "   Train Epoch: 501 [step 1/1 (0%)]\tLoss: 0.009104\n",
            "   Test set: Average loss: 0.004670, Accuracy: 727/2000 (36.35%)\n",
            "   Train Epoch: 601 [step 1/1 (0%)]\tLoss: 0.004020\n",
            "   Test set: Average loss: 0.004477, Accuracy: 762/2000 (38.10%)\n",
            "   Train Epoch: 700 [step 1/1 (0%)]\tLoss: 0.006445\n",
            "   Test set: Average loss: 0.004476, Accuracy: 768/2000 (38.40%)\n",
            "  Run execution time: train: 802.143 (s) - eval: 0.903 (s)- total: 802.143 (s)\n",
            "  Scenario 86/300 - Epochs: 700 - lr: - 0.0005 - dropout: 0.1 - Weight_decay: 0.0001252065381499946 - Grad_clip: 0.004950159553733192\n",
            "  Train time 803.946 +- 2.349 (s) - eval time 0.905 +- 0.008 (s) - total: 803.946 +- 2.349 (s) on Tesla P100-PCIE-16GB\n",
            "  Final acc over 5 instances: 37.62 +- 0.92\n",
            "\n",
            "\n",
            "Current performance summary over 86 completed scenario(s): \n",
            " - Top 9 final average accuracy:\n",
            "   + Scenario: 74 - Final average accuracy: 39.14 +- 1.58%\n",
            "   + Scenario: 72 - Final average accuracy: 39.06 +- 1.26%\n",
            "   + Scenario: 60 - Final average accuracy: 39.23 +- 1.38%\n",
            "   + Scenario: 56 - Final average accuracy: 38.98 +- 1.43%\n",
            "   + Scenario: 54 - Final average accuracy: 39.06 +- 1.74%\n",
            "   + Scenario: 51 - Final average accuracy: 39.31 +- 0.91%\n",
            "   + Scenario: 55 - Final average accuracy: 39.06 +- 0.91%\n",
            "   + Scenario: 59 - Final average accuracy: 38.97 +- 1.24%\n",
            "   + Scenario: 69 - Final average accuracy: 39.35 +- 1.48%\n",
            " - Top 9 max accuracy:\n",
            "   + Scenario: 70 - run 1 - epoch 487 - Max accuracy: 41.65\n",
            "   + Scenario: 23 - run 6 - epoch 457 - Max accuracy: 41.75\n",
            "   + Scenario: 23 - run 6 - epoch 459 - Max accuracy: 41.65\n",
            "   + Scenario: 23 - run 6 - epoch 476 - Max accuracy: 41.75\n",
            "   + Scenario: 23 - run 6 - epoch 477 - Max accuracy: 41.85\n",
            "   + Scenario: 23 - run 6 - epoch 478 - Max accuracy: 41.60\n",
            "   + Scenario: 23 - run 6 - epoch 479 - Max accuracy: 41.85\n",
            "   + Scenario: 55 - run 6 - epoch 516 - Max accuracy: 41.70\n",
            "   + Scenario: 57 - run 4 - epoch 670 - Max accuracy: 41.60\n",
            " - Top 9 least final accuracy variation:\n",
            "   + Scenario: 2 - Final average accuracy: 38.41 +- 0.73%\n",
            "   + Scenario: 17 - Final average accuracy: 38.74 +- 0.67%\n",
            "   + Scenario: 19 - Final average accuracy: 38.33 +- 0.50%\n",
            "   + Scenario: 25 - Final average accuracy: 38.60 +- 0.77%\n",
            "   + Scenario: 34 - Final average accuracy: 35.09 +- 0.69%\n",
            "   + Scenario: 62 - Final average accuracy: 38.93 +- 0.83%\n",
            "   + Scenario: 68 - Final average accuracy: 38.49 +- 0.75%\n",
            "   + Scenario: 76 - Final average accuracy: 38.69 +- 0.73%\n",
            "   + Scenario: 78 - Final average accuracy: 38.63 +- 0.73%\n",
            "\n",
            "Scenario 87/300 - Epochs: 700 - lr: - 0.0005 - dropout: 0.1 - Weight_decay: 0.0001252065381499946 - Grad_clip: 0.015119336467640998\n",
            "  Run# [1/5] - Num Samples For Training 100 - Num Samples For Val 2000\n",
            "   Train Epoch: 1 [step 1/1 (0%)]\tLoss: 0.941185\n",
            "   Test set: Average loss: 0.007097, Accuracy: 200/2000 (10.00%)\n",
            "   Train Epoch: 101 [step 1/1 (0%)]\tLoss: 0.348558\n",
            "   Test set: Average loss: 0.005223, Accuracy: 550/2000 (27.50%)\n",
            "   Train Epoch: 201 [step 1/1 (0%)]\tLoss: 0.157725\n",
            "   Test set: Average loss: 0.005110, Accuracy: 589/2000 (29.45%)\n",
            "   Train Epoch: 301 [step 1/1 (0%)]\tLoss: 0.050547\n",
            "   Test set: Average loss: 0.004818, Accuracy: 681/2000 (34.05%)\n",
            "   Train Epoch: 401 [step 1/1 (0%)]\tLoss: 0.036549\n",
            "   Test set: Average loss: 0.004756, Accuracy: 681/2000 (34.05%)\n",
            "   Train Epoch: 501 [step 1/1 (0%)]\tLoss: 0.012097\n",
            "   Test set: Average loss: 0.004762, Accuracy: 708/2000 (35.40%)\n",
            "   Train Epoch: 601 [step 1/1 (0%)]\tLoss: 0.006309\n",
            "   Test set: Average loss: 0.004713, Accuracy: 727/2000 (36.35%)\n",
            "   Train Epoch: 700 [step 1/1 (0%)]\tLoss: 0.004625\n",
            "   Test set: Average loss: 0.004692, Accuracy: 736/2000 (36.80%)\n",
            "  Run execution time: train: 803.763 (s) - eval: 0.912 (s)- total: 803.763 (s)\n",
            "  Run# [2/5] - Num Samples For Training 100 - Num Samples For Val 2000\n",
            "   Train Epoch: 1 [step 1/1 (0%)]\tLoss: 1.048884\n",
            "   Test set: Average loss: 0.008522, Accuracy: 200/2000 (10.00%)\n",
            "   Train Epoch: 101 [step 1/1 (0%)]\tLoss: 0.391019\n",
            "   Test set: Average loss: 0.004790, Accuracy: 557/2000 (27.85%)\n",
            "   Train Epoch: 201 [step 1/1 (0%)]\tLoss: 0.142048\n",
            "   Test set: Average loss: 0.004887, Accuracy: 655/2000 (32.75%)\n",
            "   Train Epoch: 301 [step 1/1 (0%)]\tLoss: 0.057770\n",
            "   Test set: Average loss: 0.004783, Accuracy: 700/2000 (35.00%)\n",
            "   Train Epoch: 401 [step 1/1 (0%)]\tLoss: 0.013992\n",
            "   Test set: Average loss: 0.004594, Accuracy: 766/2000 (38.30%)\n",
            "   Train Epoch: 501 [step 1/1 (0%)]\tLoss: 0.009381\n",
            "   Test set: Average loss: 0.004660, Accuracy: 743/2000 (37.15%)\n",
            "   Train Epoch: 601 [step 1/1 (0%)]\tLoss: 0.008057\n",
            "   Test set: Average loss: 0.004619, Accuracy: 772/2000 (38.60%)\n",
            "   Train Epoch: 700 [step 1/1 (0%)]\tLoss: 0.004332\n",
            "   Test set: Average loss: 0.004579, Accuracy: 777/2000 (38.85%)\n",
            "  Run execution time: train: 811.667 (s) - eval: 0.929 (s)- total: 811.667 (s)\n",
            "  Run# [3/5] - Num Samples For Training 100 - Num Samples For Val 2000\n",
            "   Train Epoch: 1 [step 1/1 (0%)]\tLoss: 0.915320\n",
            "   Test set: Average loss: 0.007507, Accuracy: 207/2000 (10.35%)\n",
            "   Train Epoch: 101 [step 1/1 (0%)]\tLoss: 0.392560\n",
            "   Test set: Average loss: 0.004941, Accuracy: 606/2000 (30.30%)\n",
            "   Train Epoch: 201 [step 1/1 (0%)]\tLoss: 0.129966\n",
            "   Test set: Average loss: 0.004913, Accuracy: 641/2000 (32.05%)\n",
            "   Train Epoch: 301 [step 1/1 (0%)]\tLoss: 0.033970\n",
            "   Test set: Average loss: 0.004796, Accuracy: 693/2000 (34.65%)\n",
            "   Train Epoch: 401 [step 1/1 (0%)]\tLoss: 0.013722\n",
            "   Test set: Average loss: 0.004846, Accuracy: 697/2000 (34.85%)\n",
            "   Train Epoch: 501 [step 1/1 (0%)]\tLoss: 0.003879\n",
            "   Test set: Average loss: 0.004741, Accuracy: 702/2000 (35.10%)\n",
            "   Train Epoch: 601 [step 1/1 (0%)]\tLoss: 0.003214\n",
            "   Test set: Average loss: 0.004770, Accuracy: 718/2000 (35.90%)\n",
            "   Train Epoch: 700 [step 1/1 (0%)]\tLoss: 0.002344\n",
            "   Test set: Average loss: 0.004781, Accuracy: 701/2000 (35.05%)\n",
            "  Run execution time: train: 822.683 (s) - eval: 0.922 (s)- total: 822.683 (s)\n",
            "  Run# [4/5] - Num Samples For Training 100 - Num Samples For Val 2000\n",
            "   Train Epoch: 1 [step 1/1 (0%)]\tLoss: 0.963694\n",
            "   Test set: Average loss: 0.007956, Accuracy: 163/2000 (8.15%)\n",
            "   Train Epoch: 101 [step 1/1 (0%)]\tLoss: 0.394280\n",
            "   Test set: Average loss: 0.004751, Accuracy: 611/2000 (30.55%)\n",
            "   Train Epoch: 201 [step 1/1 (0%)]\tLoss: 0.147729\n",
            "   Test set: Average loss: 0.004972, Accuracy: 622/2000 (31.10%)\n",
            "   Train Epoch: 301 [step 1/1 (0%)]\tLoss: 0.056417\n",
            "   Test set: Average loss: 0.004940, Accuracy: 625/2000 (31.25%)\n",
            "   Train Epoch: 401 [step 1/1 (0%)]\tLoss: 0.029048\n",
            "   Test set: Average loss: 0.004678, Accuracy: 743/2000 (37.15%)\n",
            "   Train Epoch: 501 [step 1/1 (0%)]\tLoss: 0.009152\n",
            "   Test set: Average loss: 0.004628, Accuracy: 764/2000 (38.20%)\n",
            "   Train Epoch: 601 [step 1/1 (0%)]\tLoss: 0.009084\n",
            "   Test set: Average loss: 0.004619, Accuracy: 746/2000 (37.30%)\n",
            "   Train Epoch: 700 [step 1/1 (0%)]\tLoss: 0.002563\n",
            "   Test set: Average loss: 0.004563, Accuracy: 761/2000 (38.05%)\n",
            "  Run execution time: train: 826.741 (s) - eval: 0.928 (s)- total: 826.741 (s)\n",
            "  Run# [5/5] - Num Samples For Training 100 - Num Samples For Val 2000\n",
            "   Train Epoch: 1 [step 1/1 (0%)]\tLoss: 0.971681\n",
            "   Test set: Average loss: 0.009114, Accuracy: 200/2000 (10.00%)\n",
            "   Train Epoch: 101 [step 1/1 (0%)]\tLoss: 0.414902\n",
            "   Test set: Average loss: 0.005087, Accuracy: 574/2000 (28.70%)\n",
            "   Train Epoch: 201 [step 1/1 (0%)]\tLoss: 0.156191\n",
            "   Test set: Average loss: 0.004594, Accuracy: 720/2000 (36.00%)\n",
            "   Train Epoch: 301 [step 1/1 (0%)]\tLoss: 0.051493\n",
            "   Test set: Average loss: 0.004793, Accuracy: 688/2000 (34.40%)\n",
            "   Train Epoch: 401 [step 1/1 (0%)]\tLoss: 0.024557\n",
            "   Test set: Average loss: 0.004673, Accuracy: 735/2000 (36.75%)\n",
            "   Train Epoch: 501 [step 1/1 (0%)]\tLoss: 0.011957\n",
            "   Test set: Average loss: 0.004669, Accuracy: 753/2000 (37.65%)\n",
            "   Train Epoch: 601 [step 1/1 (0%)]\tLoss: 0.005314\n",
            "   Test set: Average loss: 0.004520, Accuracy: 766/2000 (38.30%)\n",
            "   Train Epoch: 700 [step 1/1 (0%)]\tLoss: 0.007326\n",
            "   Test set: Average loss: 0.004514, Accuracy: 782/2000 (39.10%)\n",
            "  Run execution time: train: 822.434 (s) - eval: 0.934 (s)- total: 822.434 (s)\n",
            "  Scenario 87/300 - Epochs: 700 - lr: - 0.0005 - dropout: 0.1 - Weight_decay: 0.0001252065381499946 - Grad_clip: 0.015119336467640998\n",
            "  Train time 817.458 +- 8.477 (s) - eval time 0.925 +- 0.007 (s) - total: 817.458 +- 8.477 (s) on Tesla P100-PCIE-16GB\n",
            "  Final acc over 5 instances: 37.57 +- 1.49\n",
            "\n",
            "\n",
            "Current performance summary over 87 completed scenario(s): \n",
            " - Top 9 final average accuracy:\n",
            "   + Scenario: 69 - Final average accuracy: 39.35 +- 1.48%\n",
            "   + Scenario: 59 - Final average accuracy: 38.97 +- 1.24%\n",
            "   + Scenario: 55 - Final average accuracy: 39.06 +- 0.91%\n",
            "   + Scenario: 51 - Final average accuracy: 39.31 +- 0.91%\n",
            "   + Scenario: 54 - Final average accuracy: 39.06 +- 1.74%\n",
            "   + Scenario: 56 - Final average accuracy: 38.98 +- 1.43%\n",
            "   + Scenario: 60 - Final average accuracy: 39.23 +- 1.38%\n",
            "   + Scenario: 72 - Final average accuracy: 39.06 +- 1.26%\n",
            "   + Scenario: 74 - Final average accuracy: 39.14 +- 1.58%\n",
            " - Top 9 max accuracy:\n",
            "   + Scenario: 57 - run 4 - epoch 670 - Max accuracy: 41.60\n",
            "   + Scenario: 55 - run 6 - epoch 516 - Max accuracy: 41.70\n",
            "   + Scenario: 23 - run 6 - epoch 479 - Max accuracy: 41.85\n",
            "   + Scenario: 23 - run 6 - epoch 478 - Max accuracy: 41.60\n",
            "   + Scenario: 23 - run 6 - epoch 477 - Max accuracy: 41.85\n",
            "   + Scenario: 23 - run 6 - epoch 476 - Max accuracy: 41.75\n",
            "   + Scenario: 23 - run 6 - epoch 459 - Max accuracy: 41.65\n",
            "   + Scenario: 23 - run 6 - epoch 457 - Max accuracy: 41.75\n",
            "   + Scenario: 70 - run 1 - epoch 487 - Max accuracy: 41.65\n",
            " - Top 9 least final accuracy variation:\n",
            "   + Scenario: 2 - Final average accuracy: 38.41 +- 0.73%\n",
            "   + Scenario: 17 - Final average accuracy: 38.74 +- 0.67%\n",
            "   + Scenario: 19 - Final average accuracy: 38.33 +- 0.50%\n",
            "   + Scenario: 25 - Final average accuracy: 38.60 +- 0.77%\n",
            "   + Scenario: 34 - Final average accuracy: 35.09 +- 0.69%\n",
            "   + Scenario: 62 - Final average accuracy: 38.93 +- 0.83%\n",
            "   + Scenario: 68 - Final average accuracy: 38.49 +- 0.75%\n",
            "   + Scenario: 76 - Final average accuracy: 38.69 +- 0.73%\n",
            "   + Scenario: 78 - Final average accuracy: 38.63 +- 0.73%\n",
            "\n",
            "Scenario 88/300 - Epochs: 700 - lr: - 0.0005 - dropout: 0.1 - Weight_decay: 0.0001252065381499946 - Grad_clip: 0.01567667719550606\n",
            "  Run# [1/5] - Num Samples For Training 100 - Num Samples For Val 2000\n",
            "   Train Epoch: 1 [step 1/1 (0%)]\tLoss: 1.095116\n",
            "   Test set: Average loss: 0.007959, Accuracy: 165/2000 (8.25%)\n",
            "   Train Epoch: 101 [step 1/1 (0%)]\tLoss: 0.384753\n",
            "   Test set: Average loss: 0.005047, Accuracy: 559/2000 (27.95%)\n",
            "   Train Epoch: 201 [step 1/1 (0%)]\tLoss: 0.123071\n",
            "   Test set: Average loss: 0.004830, Accuracy: 679/2000 (33.95%)\n",
            "   Train Epoch: 301 [step 1/1 (0%)]\tLoss: 0.029961\n",
            "   Test set: Average loss: 0.004836, Accuracy: 669/2000 (33.45%)\n",
            "   Train Epoch: 401 [step 1/1 (0%)]\tLoss: 0.024098\n",
            "   Test set: Average loss: 0.004983, Accuracy: 661/2000 (33.05%)\n",
            "   Train Epoch: 501 [step 1/1 (0%)]\tLoss: 0.003664\n",
            "   Test set: Average loss: 0.004785, Accuracy: 700/2000 (35.00%)\n",
            "   Train Epoch: 601 [step 1/1 (0%)]\tLoss: 0.005487\n",
            "   Test set: Average loss: 0.004660, Accuracy: 724/2000 (36.20%)\n",
            "   Train Epoch: 700 [step 1/1 (0%)]\tLoss: 0.004832\n",
            "   Test set: Average loss: 0.004615, Accuracy: 745/2000 (37.25%)\n",
            "  Run execution time: train: 825.198 (s) - eval: 0.930 (s)- total: 825.198 (s)\n",
            "  Run# [2/5] - Num Samples For Training 100 - Num Samples For Val 2000\n",
            "   Train Epoch: 1 [step 1/1 (0%)]\tLoss: 0.913330\n",
            "   Test set: Average loss: 0.006816, Accuracy: 199/2000 (9.95%)\n",
            "   Train Epoch: 101 [step 1/1 (0%)]\tLoss: 0.396786\n",
            "   Test set: Average loss: 0.005030, Accuracy: 514/2000 (25.70%)\n",
            "   Train Epoch: 201 [step 1/1 (0%)]\tLoss: 0.120538\n",
            "   Test set: Average loss: 0.005077, Accuracy: 684/2000 (34.20%)\n",
            "   Train Epoch: 301 [step 1/1 (0%)]\tLoss: 0.033591\n",
            "   Test set: Average loss: 0.004623, Accuracy: 727/2000 (36.35%)\n",
            "   Train Epoch: 401 [step 1/1 (0%)]\tLoss: 0.026024\n",
            "   Test set: Average loss: 0.004821, Accuracy: 681/2000 (34.05%)\n",
            "   Train Epoch: 501 [step 1/1 (0%)]\tLoss: 0.010174\n",
            "   Test set: Average loss: 0.004664, Accuracy: 780/2000 (39.00%)\n",
            "   Train Epoch: 601 [step 1/1 (0%)]\tLoss: 0.003372\n",
            "   Test set: Average loss: 0.004591, Accuracy: 781/2000 (39.05%)\n",
            "   Train Epoch: 700 [step 1/1 (0%)]\tLoss: 0.003751\n",
            "   Test set: Average loss: 0.004573, Accuracy: 776/2000 (38.80%)\n",
            "  Run execution time: train: 822.352 (s) - eval: 0.909 (s)- total: 822.352 (s)\n",
            "  Run# [3/5] - Num Samples For Training 100 - Num Samples For Val 2000\n",
            "   Train Epoch: 1 [step 1/1 (0%)]\tLoss: 0.829394\n",
            "   Test set: Average loss: 0.006789, Accuracy: 200/2000 (10.00%)\n",
            "   Train Epoch: 101 [step 1/1 (0%)]\tLoss: 0.390550\n",
            "   Test set: Average loss: 0.004961, Accuracy: 599/2000 (29.95%)\n",
            "   Train Epoch: 201 [step 1/1 (0%)]\tLoss: 0.156000\n",
            "   Test set: Average loss: 0.005150, Accuracy: 643/2000 (32.15%)\n",
            "   Train Epoch: 301 [step 1/1 (0%)]\tLoss: 0.035121\n",
            "   Test set: Average loss: 0.004938, Accuracy: 651/2000 (32.55%)\n",
            "   Train Epoch: 401 [step 1/1 (0%)]\tLoss: 0.024193\n",
            "   Test set: Average loss: 0.004863, Accuracy: 655/2000 (32.75%)\n",
            "   Train Epoch: 501 [step 1/1 (0%)]\tLoss: 0.004447\n",
            "   Test set: Average loss: 0.004849, Accuracy: 695/2000 (34.75%)\n",
            "   Train Epoch: 601 [step 1/1 (0%)]\tLoss: 0.008846\n",
            "   Test set: Average loss: 0.004814, Accuracy: 685/2000 (34.25%)\n",
            "   Train Epoch: 700 [step 1/1 (0%)]\tLoss: 0.002880\n",
            "   Test set: Average loss: 0.004736, Accuracy: 703/2000 (35.15%)\n",
            "  Run execution time: train: 823.194 (s) - eval: 0.922 (s)- total: 823.194 (s)\n",
            "  Run# [4/5] - Num Samples For Training 100 - Num Samples For Val 2000\n",
            "   Train Epoch: 1 [step 1/1 (0%)]\tLoss: 1.019337\n",
            "   Test set: Average loss: 0.008168, Accuracy: 200/2000 (10.00%)\n",
            "   Train Epoch: 101 [step 1/1 (0%)]\tLoss: 0.411226\n",
            "   Test set: Average loss: 0.005015, Accuracy: 535/2000 (26.75%)\n",
            "   Train Epoch: 201 [step 1/1 (0%)]\tLoss: 0.101372\n",
            "   Test set: Average loss: 0.004830, Accuracy: 705/2000 (35.25%)\n",
            "   Train Epoch: 301 [step 1/1 (0%)]\tLoss: 0.028781\n",
            "   Test set: Average loss: 0.004642, Accuracy: 778/2000 (38.90%)\n",
            "   Train Epoch: 401 [step 1/1 (0%)]\tLoss: 0.016004\n",
            "   Test set: Average loss: 0.004737, Accuracy: 732/2000 (36.60%)\n",
            "   Train Epoch: 501 [step 1/1 (0%)]\tLoss: 0.007682\n",
            "   Test set: Average loss: 0.004864, Accuracy: 687/2000 (34.35%)\n",
            "   Train Epoch: 601 [step 1/1 (0%)]\tLoss: 0.006523\n",
            "   Test set: Average loss: 0.004616, Accuracy: 754/2000 (37.70%)\n",
            "   Train Epoch: 700 [step 1/1 (0%)]\tLoss: 0.002774\n",
            "   Test set: Average loss: 0.004618, Accuracy: 748/2000 (37.40%)\n",
            "  Run execution time: train: 816.850 (s) - eval: 0.929 (s)- total: 816.850 (s)\n",
            "  Run# [5/5] - Num Samples For Training 100 - Num Samples For Val 2000\n",
            "   Train Epoch: 1 [step 1/1 (0%)]\tLoss: 0.973609\n",
            "   Test set: Average loss: 0.006662, Accuracy: 198/2000 (9.90%)\n",
            "   Train Epoch: 101 [step 1/1 (0%)]\tLoss: 0.419307\n",
            "   Test set: Average loss: 0.004637, Accuracy: 629/2000 (31.45%)\n",
            "   Train Epoch: 201 [step 1/1 (0%)]\tLoss: 0.184706\n",
            "   Test set: Average loss: 0.004674, Accuracy: 739/2000 (36.95%)\n",
            "   Train Epoch: 301 [step 1/1 (0%)]\tLoss: 0.052742\n",
            "   Test set: Average loss: 0.004850, Accuracy: 714/2000 (35.70%)\n",
            "   Train Epoch: 401 [step 1/1 (0%)]\tLoss: 0.014179\n",
            "   Test set: Average loss: 0.004687, Accuracy: 737/2000 (36.85%)\n",
            "   Train Epoch: 501 [step 1/1 (0%)]\tLoss: 0.008777\n",
            "   Test set: Average loss: 0.004439, Accuracy: 780/2000 (39.00%)\n",
            "   Train Epoch: 601 [step 1/1 (0%)]\tLoss: 0.005269\n",
            "   Test set: Average loss: 0.004447, Accuracy: 793/2000 (39.65%)\n",
            "   Train Epoch: 700 [step 1/1 (0%)]\tLoss: 0.003371\n",
            "   Test set: Average loss: 0.004443, Accuracy: 793/2000 (39.65%)\n",
            "  Run execution time: train: 813.945 (s) - eval: 0.931 (s)- total: 813.945 (s)\n",
            "  Scenario 88/300 - Epochs: 700 - lr: - 0.0005 - dropout: 0.1 - Weight_decay: 0.0001252065381499946 - Grad_clip: 0.01567667719550606\n",
            "  Train time 820.308 +- 4.216 (s) - eval time 0.924 +- 0.008 (s) - total: 820.308 +- 4.216 (s) on Tesla P100-PCIE-16GB\n",
            "  Final acc over 5 instances: 37.65 +- 1.54\n",
            "\n",
            "\n",
            "Current performance summary over 88 completed scenario(s): \n",
            " - Top 9 final average accuracy:\n",
            "   + Scenario: 74 - Final average accuracy: 39.14 +- 1.58%\n",
            "   + Scenario: 72 - Final average accuracy: 39.06 +- 1.26%\n",
            "   + Scenario: 60 - Final average accuracy: 39.23 +- 1.38%\n",
            "   + Scenario: 56 - Final average accuracy: 38.98 +- 1.43%\n",
            "   + Scenario: 54 - Final average accuracy: 39.06 +- 1.74%\n",
            "   + Scenario: 51 - Final average accuracy: 39.31 +- 0.91%\n",
            "   + Scenario: 55 - Final average accuracy: 39.06 +- 0.91%\n",
            "   + Scenario: 59 - Final average accuracy: 38.97 +- 1.24%\n",
            "   + Scenario: 69 - Final average accuracy: 39.35 +- 1.48%\n",
            " - Top 9 max accuracy:\n",
            "   + Scenario: 70 - run 1 - epoch 487 - Max accuracy: 41.65\n",
            "   + Scenario: 23 - run 6 - epoch 457 - Max accuracy: 41.75\n",
            "   + Scenario: 23 - run 6 - epoch 459 - Max accuracy: 41.65\n",
            "   + Scenario: 23 - run 6 - epoch 476 - Max accuracy: 41.75\n",
            "   + Scenario: 23 - run 6 - epoch 477 - Max accuracy: 41.85\n",
            "   + Scenario: 23 - run 6 - epoch 478 - Max accuracy: 41.60\n",
            "   + Scenario: 23 - run 6 - epoch 479 - Max accuracy: 41.85\n",
            "   + Scenario: 55 - run 6 - epoch 516 - Max accuracy: 41.70\n",
            "   + Scenario: 57 - run 4 - epoch 670 - Max accuracy: 41.60\n",
            " - Top 9 least final accuracy variation:\n",
            "   + Scenario: 2 - Final average accuracy: 38.41 +- 0.73%\n",
            "   + Scenario: 17 - Final average accuracy: 38.74 +- 0.67%\n",
            "   + Scenario: 19 - Final average accuracy: 38.33 +- 0.50%\n",
            "   + Scenario: 25 - Final average accuracy: 38.60 +- 0.77%\n",
            "   + Scenario: 34 - Final average accuracy: 35.09 +- 0.69%\n",
            "   + Scenario: 62 - Final average accuracy: 38.93 +- 0.83%\n",
            "   + Scenario: 68 - Final average accuracy: 38.49 +- 0.75%\n",
            "   + Scenario: 76 - Final average accuracy: 38.69 +- 0.73%\n",
            "   + Scenario: 78 - Final average accuracy: 38.63 +- 0.73%\n",
            "\n",
            "Scenario 89/300 - Epochs: 700 - lr: - 0.0005 - dropout: 0.1 - Weight_decay: 0.0001252065381499946 - Grad_clip: 0.02576638574613588\n",
            "  Run# [1/5] - Num Samples For Training 100 - Num Samples For Val 2000\n",
            "   Train Epoch: 1 [step 1/1 (0%)]\tLoss: 0.931885\n",
            "   Test set: Average loss: 0.007982, Accuracy: 221/2000 (11.05%)\n",
            "   Train Epoch: 101 [step 1/1 (0%)]\tLoss: 0.389311\n",
            "   Test set: Average loss: 0.005205, Accuracy: 546/2000 (27.30%)\n",
            "   Train Epoch: 201 [step 1/1 (0%)]\tLoss: 0.141015\n",
            "   Test set: Average loss: 0.004940, Accuracy: 683/2000 (34.15%)\n",
            "   Train Epoch: 301 [step 1/1 (0%)]\tLoss: 0.056321\n",
            "   Test set: Average loss: 0.004761, Accuracy: 698/2000 (34.90%)\n",
            "   Train Epoch: 401 [step 1/1 (0%)]\tLoss: 0.019637\n",
            "   Test set: Average loss: 0.004719, Accuracy: 738/2000 (36.90%)\n",
            "   Train Epoch: 501 [step 1/1 (0%)]\tLoss: 0.012873\n",
            "   Test set: Average loss: 0.004656, Accuracy: 751/2000 (37.55%)\n",
            "   Train Epoch: 601 [step 1/1 (0%)]\tLoss: 0.002813\n",
            "   Test set: Average loss: 0.004637, Accuracy: 752/2000 (37.60%)\n",
            "   Train Epoch: 700 [step 1/1 (0%)]\tLoss: 0.002223\n",
            "   Test set: Average loss: 0.004594, Accuracy: 764/2000 (38.20%)\n",
            "  Run execution time: train: 813.070 (s) - eval: 0.894 (s)- total: 813.070 (s)\n",
            "  Run# [2/5] - Num Samples For Training 100 - Num Samples For Val 2000\n",
            "   Train Epoch: 1 [step 1/1 (0%)]\tLoss: 0.975505\n",
            "   Test set: Average loss: 0.006784, Accuracy: 169/2000 (8.45%)\n",
            "   Train Epoch: 101 [step 1/1 (0%)]\tLoss: 0.427684\n",
            "   Test set: Average loss: 0.005061, Accuracy: 526/2000 (26.30%)\n",
            "   Train Epoch: 201 [step 1/1 (0%)]\tLoss: 0.116328\n",
            "   Test set: Average loss: 0.005107, Accuracy: 650/2000 (32.50%)\n",
            "   Train Epoch: 301 [step 1/1 (0%)]\tLoss: 0.050172\n",
            "   Test set: Average loss: 0.005031, Accuracy: 681/2000 (34.05%)\n",
            "   Train Epoch: 401 [step 1/1 (0%)]\tLoss: 0.012652\n",
            "   Test set: Average loss: 0.004797, Accuracy: 714/2000 (35.70%)\n",
            "   Train Epoch: 501 [step 1/1 (0%)]\tLoss: 0.007026\n",
            "   Test set: Average loss: 0.004897, Accuracy: 675/2000 (33.75%)\n",
            "   Train Epoch: 601 [step 1/1 (0%)]\tLoss: 0.006295\n",
            "   Test set: Average loss: 0.004708, Accuracy: 731/2000 (36.55%)\n",
            "   Train Epoch: 700 [step 1/1 (0%)]\tLoss: 0.004382\n",
            "   Test set: Average loss: 0.004680, Accuracy: 738/2000 (36.90%)\n",
            "  Run execution time: train: 812.701 (s) - eval: 0.915 (s)- total: 812.701 (s)\n",
            "  Run# [3/5] - Num Samples For Training 100 - Num Samples For Val 2000\n",
            "   Train Epoch: 1 [step 1/1 (0%)]\tLoss: 0.963148\n",
            "   Test set: Average loss: 0.007013, Accuracy: 196/2000 (9.80%)\n",
            "   Train Epoch: 101 [step 1/1 (0%)]\tLoss: 0.387012\n",
            "   Test set: Average loss: 0.004947, Accuracy: 589/2000 (29.45%)\n",
            "   Train Epoch: 201 [step 1/1 (0%)]\tLoss: 0.099158\n",
            "   Test set: Average loss: 0.005163, Accuracy: 620/2000 (31.00%)\n",
            "   Train Epoch: 301 [step 1/1 (0%)]\tLoss: 0.028134\n",
            "   Test set: Average loss: 0.004772, Accuracy: 674/2000 (33.70%)\n",
            "   Train Epoch: 401 [step 1/1 (0%)]\tLoss: 0.018318\n",
            "   Test set: Average loss: 0.004664, Accuracy: 739/2000 (36.95%)\n",
            "   Train Epoch: 501 [step 1/1 (0%)]\tLoss: 0.009662\n",
            "   Test set: Average loss: 0.004849, Accuracy: 676/2000 (33.80%)\n",
            "   Train Epoch: 601 [step 1/1 (0%)]\tLoss: 0.003495\n",
            "   Test set: Average loss: 0.004818, Accuracy: 685/2000 (34.25%)\n",
            "   Train Epoch: 700 [step 1/1 (0%)]\tLoss: 0.011537\n",
            "   Test set: Average loss: 0.004802, Accuracy: 690/2000 (34.50%)\n",
            "  Run execution time: train: 807.767 (s) - eval: 0.950 (s)- total: 807.767 (s)\n",
            "  Run# [4/5] - Num Samples For Training 100 - Num Samples For Val 2000\n",
            "   Train Epoch: 1 [step 1/1 (0%)]\tLoss: 0.973491\n",
            "   Test set: Average loss: 0.007896, Accuracy: 200/2000 (10.00%)\n",
            "   Train Epoch: 101 [step 1/1 (0%)]\tLoss: 0.404845\n",
            "   Test set: Average loss: 0.005108, Accuracy: 495/2000 (24.75%)\n",
            "   Train Epoch: 201 [step 1/1 (0%)]\tLoss: 0.153673\n",
            "   Test set: Average loss: 0.004751, Accuracy: 661/2000 (33.05%)\n",
            "   Train Epoch: 301 [step 1/1 (0%)]\tLoss: 0.037691\n",
            "   Test set: Average loss: 0.005170, Accuracy: 603/2000 (30.15%)\n",
            "   Train Epoch: 401 [step 1/1 (0%)]\tLoss: 0.019130\n",
            "   Test set: Average loss: 0.004784, Accuracy: 713/2000 (35.65%)\n",
            "   Train Epoch: 501 [step 1/1 (0%)]\tLoss: 0.013153\n",
            "   Test set: Average loss: 0.004874, Accuracy: 676/2000 (33.80%)\n",
            "   Train Epoch: 601 [step 1/1 (0%)]\tLoss: 0.003903\n",
            "   Test set: Average loss: 0.004699, Accuracy: 731/2000 (36.55%)\n",
            "   Train Epoch: 700 [step 1/1 (0%)]\tLoss: 0.009147\n",
            "   Test set: Average loss: 0.004685, Accuracy: 735/2000 (36.75%)\n",
            "  Run execution time: train: 804.752 (s) - eval: 0.898 (s)- total: 804.752 (s)\n",
            "  Run# [5/5] - Num Samples For Training 100 - Num Samples For Val 2000\n",
            "   Train Epoch: 1 [step 1/1 (0%)]\tLoss: 0.893055\n",
            "   Test set: Average loss: 0.006725, Accuracy: 268/2000 (13.40%)\n",
            "   Train Epoch: 101 [step 1/1 (0%)]\tLoss: 0.423676\n",
            "   Test set: Average loss: 0.004672, Accuracy: 649/2000 (32.45%)\n",
            "   Train Epoch: 201 [step 1/1 (0%)]\tLoss: 0.113891\n",
            "   Test set: Average loss: 0.004599, Accuracy: 727/2000 (36.35%)\n",
            "   Train Epoch: 301 [step 1/1 (0%)]\tLoss: 0.047071\n",
            "   Test set: Average loss: 0.004435, Accuracy: 789/2000 (39.45%)\n",
            "   Train Epoch: 401 [step 1/1 (0%)]\tLoss: 0.052591\n",
            "   Test set: Average loss: 0.004930, Accuracy: 684/2000 (34.20%)\n",
            "   Train Epoch: 501 [step 1/1 (0%)]\tLoss: 0.008468\n",
            "   Test set: Average loss: 0.004540, Accuracy: 771/2000 (38.55%)\n",
            "   Train Epoch: 601 [step 1/1 (0%)]\tLoss: 0.004016\n",
            "   Test set: Average loss: 0.004467, Accuracy: 783/2000 (39.15%)\n",
            "   Train Epoch: 700 [step 1/1 (0%)]\tLoss: 0.004686\n",
            "   Test set: Average loss: 0.004443, Accuracy: 790/2000 (39.50%)\n",
            "  Run execution time: train: 803.980 (s) - eval: 0.913 (s)- total: 803.980 (s)\n",
            "  Scenario 89/300 - Epochs: 700 - lr: - 0.0005 - dropout: 0.1 - Weight_decay: 0.0001252065381499946 - Grad_clip: 0.02576638574613588\n",
            "  Train time 808.454 +- 3.835 (s) - eval time 0.914 +- 0.020 (s) - total: 808.454 +- 3.835 (s) on Tesla P100-PCIE-16GB\n",
            "  Final acc over 5 instances: 37.17 +- 1.67\n",
            "\n",
            "\n",
            "Current performance summary over 89 completed scenario(s): \n",
            " - Top 9 final average accuracy:\n",
            "   + Scenario: 69 - Final average accuracy: 39.35 +- 1.48%\n",
            "   + Scenario: 59 - Final average accuracy: 38.97 +- 1.24%\n",
            "   + Scenario: 55 - Final average accuracy: 39.06 +- 0.91%\n",
            "   + Scenario: 51 - Final average accuracy: 39.31 +- 0.91%\n",
            "   + Scenario: 54 - Final average accuracy: 39.06 +- 1.74%\n",
            "   + Scenario: 56 - Final average accuracy: 38.98 +- 1.43%\n",
            "   + Scenario: 60 - Final average accuracy: 39.23 +- 1.38%\n",
            "   + Scenario: 72 - Final average accuracy: 39.06 +- 1.26%\n",
            "   + Scenario: 74 - Final average accuracy: 39.14 +- 1.58%\n",
            " - Top 9 max accuracy:\n",
            "   + Scenario: 57 - run 4 - epoch 670 - Max accuracy: 41.60\n",
            "   + Scenario: 55 - run 6 - epoch 516 - Max accuracy: 41.70\n",
            "   + Scenario: 23 - run 6 - epoch 479 - Max accuracy: 41.85\n",
            "   + Scenario: 23 - run 6 - epoch 478 - Max accuracy: 41.60\n",
            "   + Scenario: 23 - run 6 - epoch 477 - Max accuracy: 41.85\n",
            "   + Scenario: 23 - run 6 - epoch 476 - Max accuracy: 41.75\n",
            "   + Scenario: 23 - run 6 - epoch 459 - Max accuracy: 41.65\n",
            "   + Scenario: 23 - run 6 - epoch 457 - Max accuracy: 41.75\n",
            "   + Scenario: 70 - run 1 - epoch 487 - Max accuracy: 41.65\n",
            " - Top 9 least final accuracy variation:\n",
            "   + Scenario: 2 - Final average accuracy: 38.41 +- 0.73%\n",
            "   + Scenario: 17 - Final average accuracy: 38.74 +- 0.67%\n",
            "   + Scenario: 19 - Final average accuracy: 38.33 +- 0.50%\n",
            "   + Scenario: 25 - Final average accuracy: 38.60 +- 0.77%\n",
            "   + Scenario: 34 - Final average accuracy: 35.09 +- 0.69%\n",
            "   + Scenario: 62 - Final average accuracy: 38.93 +- 0.83%\n",
            "   + Scenario: 68 - Final average accuracy: 38.49 +- 0.75%\n",
            "   + Scenario: 76 - Final average accuracy: 38.69 +- 0.73%\n",
            "   + Scenario: 78 - Final average accuracy: 38.63 +- 0.73%\n",
            "\n",
            "Scenario 90/300 - Epochs: 700 - lr: - 0.0005 - dropout: 0.1 - Weight_decay: 0.0001252065381499946 - Grad_clip: 0.07257005721594274\n",
            "  Run# [1/5] - Num Samples For Training 100 - Num Samples For Val 2000\n",
            "   Train Epoch: 1 [step 1/1 (0%)]\tLoss: 1.108080\n",
            "   Test set: Average loss: 0.009247, Accuracy: 204/2000 (10.20%)\n",
            "   Train Epoch: 101 [step 1/1 (0%)]\tLoss: 0.417397\n",
            "   Test set: Average loss: 0.004920, Accuracy: 598/2000 (29.90%)\n",
            "   Train Epoch: 201 [step 1/1 (0%)]\tLoss: 0.102068\n",
            "   Test set: Average loss: 0.005135, Accuracy: 583/2000 (29.15%)\n",
            "   Train Epoch: 301 [step 1/1 (0%)]\tLoss: 0.025964\n",
            "   Test set: Average loss: 0.004789, Accuracy: 682/2000 (34.10%)\n",
            "   Train Epoch: 401 [step 1/1 (0%)]\tLoss: 0.019341\n",
            "   Test set: Average loss: 0.004590, Accuracy: 743/2000 (37.15%)\n",
            "   Train Epoch: 501 [step 1/1 (0%)]\tLoss: 0.015946\n",
            "   Test set: Average loss: 0.004830, Accuracy: 705/2000 (35.25%)\n",
            "   Train Epoch: 601 [step 1/1 (0%)]\tLoss: 0.004080\n",
            "   Test set: Average loss: 0.004650, Accuracy: 747/2000 (37.35%)\n",
            "   Train Epoch: 700 [step 1/1 (0%)]\tLoss: 0.002258\n",
            "   Test set: Average loss: 0.004620, Accuracy: 756/2000 (37.80%)\n",
            "  Run execution time: train: 806.182 (s) - eval: 0.925 (s)- total: 806.182 (s)\n",
            "  Run# [2/5] - Num Samples For Training 100 - Num Samples For Val 2000\n",
            "   Train Epoch: 1 [step 1/1 (0%)]\tLoss: 0.909990\n",
            "   Test set: Average loss: 0.007614, Accuracy: 202/2000 (10.10%)\n",
            "   Train Epoch: 101 [step 1/1 (0%)]\tLoss: 0.422974\n",
            "   Test set: Average loss: 0.004999, Accuracy: 557/2000 (27.85%)\n",
            "   Train Epoch: 201 [step 1/1 (0%)]\tLoss: 0.134798\n",
            "   Test set: Average loss: 0.004872, Accuracy: 650/2000 (32.50%)\n",
            "   Train Epoch: 301 [step 1/1 (0%)]\tLoss: 0.043167\n",
            "   Test set: Average loss: 0.004940, Accuracy: 690/2000 (34.50%)\n",
            "   Train Epoch: 401 [step 1/1 (0%)]\tLoss: 0.019289\n",
            "   Test set: Average loss: 0.004583, Accuracy: 749/2000 (37.45%)\n",
            "   Train Epoch: 501 [step 1/1 (0%)]\tLoss: 0.010130\n",
            "   Test set: Average loss: 0.004915, Accuracy: 685/2000 (34.25%)\n",
            "   Train Epoch: 601 [step 1/1 (0%)]\tLoss: 0.002457\n",
            "   Test set: Average loss: 0.004686, Accuracy: 736/2000 (36.80%)\n",
            "   Train Epoch: 700 [step 1/1 (0%)]\tLoss: 0.001809\n",
            "   Test set: Average loss: 0.004671, Accuracy: 748/2000 (37.40%)\n",
            "  Run execution time: train: 790.743 (s) - eval: 0.894 (s)- total: 790.743 (s)\n",
            "  Run# [3/5] - Num Samples For Training 100 - Num Samples For Val 2000\n",
            "   Train Epoch: 1 [step 1/1 (0%)]\tLoss: 0.975377\n",
            "   Test set: Average loss: 0.007105, Accuracy: 200/2000 (10.00%)\n",
            "   Train Epoch: 101 [step 1/1 (0%)]\tLoss: 0.426409\n",
            "   Test set: Average loss: 0.005099, Accuracy: 588/2000 (29.40%)\n",
            "   Train Epoch: 201 [step 1/1 (0%)]\tLoss: 0.117383\n",
            "   Test set: Average loss: 0.004803, Accuracy: 680/2000 (34.00%)\n",
            "   Train Epoch: 301 [step 1/1 (0%)]\tLoss: 0.057894\n",
            "   Test set: Average loss: 0.004778, Accuracy: 675/2000 (33.75%)\n",
            "   Train Epoch: 401 [step 1/1 (0%)]\tLoss: 0.014142\n",
            "   Test set: Average loss: 0.004877, Accuracy: 678/2000 (33.90%)\n",
            "   Train Epoch: 501 [step 1/1 (0%)]\tLoss: 0.008047\n",
            "   Test set: Average loss: 0.004836, Accuracy: 676/2000 (33.80%)\n",
            "   Train Epoch: 601 [step 1/1 (0%)]\tLoss: 0.004130\n",
            "   Test set: Average loss: 0.004815, Accuracy: 680/2000 (34.00%)\n",
            "   Train Epoch: 700 [step 1/1 (0%)]\tLoss: 0.003022\n",
            "   Test set: Average loss: 0.004797, Accuracy: 680/2000 (34.00%)\n",
            "  Run execution time: train: 791.813 (s) - eval: 0.877 (s)- total: 791.813 (s)\n",
            "  Run# [4/5] - Num Samples For Training 100 - Num Samples For Val 2000\n",
            "   Train Epoch: 1 [step 1/1 (0%)]\tLoss: 0.954867\n",
            "   Test set: Average loss: 0.008283, Accuracy: 200/2000 (10.00%)\n",
            "   Train Epoch: 101 [step 1/1 (0%)]\tLoss: 0.427725\n",
            "   Test set: Average loss: 0.004798, Accuracy: 604/2000 (30.20%)\n",
            "   Train Epoch: 201 [step 1/1 (0%)]\tLoss: 0.122658\n",
            "   Test set: Average loss: 0.004742, Accuracy: 656/2000 (32.80%)\n",
            "   Train Epoch: 301 [step 1/1 (0%)]\tLoss: 0.024178\n",
            "   Test set: Average loss: 0.005045, Accuracy: 627/2000 (31.35%)\n",
            "   Train Epoch: 401 [step 1/1 (0%)]\tLoss: 0.013661\n",
            "   Test set: Average loss: 0.004956, Accuracy: 686/2000 (34.30%)\n",
            "   Train Epoch: 501 [step 1/1 (0%)]\tLoss: 0.008933\n",
            "   Test set: Average loss: 0.004570, Accuracy: 752/2000 (37.60%)\n",
            "   Train Epoch: 601 [step 1/1 (0%)]\tLoss: 0.002686\n",
            "   Test set: Average loss: 0.004566, Accuracy: 778/2000 (38.90%)\n",
            "   Train Epoch: 700 [step 1/1 (0%)]\tLoss: 0.003143\n",
            "   Test set: Average loss: 0.004502, Accuracy: 782/2000 (39.10%)\n",
            "  Run execution time: train: 797.227 (s) - eval: 0.912 (s)- total: 797.227 (s)\n",
            "  Run# [5/5] - Num Samples For Training 100 - Num Samples For Val 2000\n",
            "   Train Epoch: 1 [step 1/1 (0%)]\tLoss: 0.932379\n",
            "   Test set: Average loss: 0.008228, Accuracy: 200/2000 (10.00%)\n",
            "   Train Epoch: 101 [step 1/1 (0%)]\tLoss: 0.396223\n",
            "   Test set: Average loss: 0.004679, Accuracy: 625/2000 (31.25%)\n",
            "   Train Epoch: 201 [step 1/1 (0%)]\tLoss: 0.140320\n",
            "   Test set: Average loss: 0.004826, Accuracy: 662/2000 (33.10%)\n",
            "   Train Epoch: 301 [step 1/1 (0%)]\tLoss: 0.037304\n",
            "   Test set: Average loss: 0.004597, Accuracy: 745/2000 (37.25%)\n",
            "   Train Epoch: 401 [step 1/1 (0%)]\tLoss: 0.016308\n",
            "   Test set: Average loss: 0.004587, Accuracy: 766/2000 (38.30%)\n",
            "   Train Epoch: 501 [step 1/1 (0%)]\tLoss: 0.006616\n",
            "   Test set: Average loss: 0.004648, Accuracy: 743/2000 (37.15%)\n",
            "   Train Epoch: 601 [step 1/1 (0%)]\tLoss: 0.003673\n",
            "   Test set: Average loss: 0.004492, Accuracy: 781/2000 (39.05%)\n",
            "   Train Epoch: 700 [step 1/1 (0%)]\tLoss: 0.002424\n",
            "   Test set: Average loss: 0.004544, Accuracy: 786/2000 (39.30%)\n",
            "  Run execution time: train: 805.182 (s) - eval: 0.907 (s)- total: 805.182 (s)\n",
            "  Scenario 90/300 - Epochs: 700 - lr: - 0.0005 - dropout: 0.1 - Weight_decay: 0.0001252065381499946 - Grad_clip: 0.07257005721594274\n",
            "  Train time 798.229 +- 6.478 (s) - eval time 0.903 +- 0.016 (s) - total: 798.229 +- 6.478 (s) on Tesla P100-PCIE-16GB\n",
            "  Final acc over 5 instances: 37.52 +- 1.91\n",
            "\n",
            "\n",
            "Current performance summary over 90 completed scenario(s): \n",
            " - Top 9 final average accuracy:\n",
            "   + Scenario: 74 - Final average accuracy: 39.14 +- 1.58%\n",
            "   + Scenario: 72 - Final average accuracy: 39.06 +- 1.26%\n",
            "   + Scenario: 60 - Final average accuracy: 39.23 +- 1.38%\n",
            "   + Scenario: 56 - Final average accuracy: 38.98 +- 1.43%\n",
            "   + Scenario: 54 - Final average accuracy: 39.06 +- 1.74%\n",
            "   + Scenario: 51 - Final average accuracy: 39.31 +- 0.91%\n",
            "   + Scenario: 55 - Final average accuracy: 39.06 +- 0.91%\n",
            "   + Scenario: 59 - Final average accuracy: 38.97 +- 1.24%\n",
            "   + Scenario: 69 - Final average accuracy: 39.35 +- 1.48%\n",
            " - Top 9 max accuracy:\n",
            "   + Scenario: 70 - run 1 - epoch 487 - Max accuracy: 41.65\n",
            "   + Scenario: 23 - run 6 - epoch 457 - Max accuracy: 41.75\n",
            "   + Scenario: 23 - run 6 - epoch 459 - Max accuracy: 41.65\n",
            "   + Scenario: 23 - run 6 - epoch 476 - Max accuracy: 41.75\n",
            "   + Scenario: 23 - run 6 - epoch 477 - Max accuracy: 41.85\n",
            "   + Scenario: 23 - run 6 - epoch 478 - Max accuracy: 41.60\n",
            "   + Scenario: 23 - run 6 - epoch 479 - Max accuracy: 41.85\n",
            "   + Scenario: 55 - run 6 - epoch 516 - Max accuracy: 41.70\n",
            "   + Scenario: 57 - run 4 - epoch 670 - Max accuracy: 41.60\n",
            " - Top 9 least final accuracy variation:\n",
            "   + Scenario: 2 - Final average accuracy: 38.41 +- 0.73%\n",
            "   + Scenario: 17 - Final average accuracy: 38.74 +- 0.67%\n",
            "   + Scenario: 19 - Final average accuracy: 38.33 +- 0.50%\n",
            "   + Scenario: 25 - Final average accuracy: 38.60 +- 0.77%\n",
            "   + Scenario: 34 - Final average accuracy: 35.09 +- 0.69%\n",
            "   + Scenario: 62 - Final average accuracy: 38.93 +- 0.83%\n",
            "   + Scenario: 68 - Final average accuracy: 38.49 +- 0.75%\n",
            "   + Scenario: 76 - Final average accuracy: 38.69 +- 0.73%\n",
            "   + Scenario: 78 - Final average accuracy: 38.63 +- 0.73%\n",
            "\n",
            "Scenario 91/300 - Epochs: 700 - lr: - 0.0005 - dropout: 0.1 - Weight_decay: 0.00016051911333587627 - Grad_clip: 0.004950159553733192\n",
            "  Run# [1/5] - Num Samples For Training 100 - Num Samples For Val 2000\n",
            "   Train Epoch: 1 [step 1/1 (0%)]\tLoss: 0.911852\n",
            "   Test set: Average loss: 0.007494, Accuracy: 199/2000 (9.95%)\n",
            "   Train Epoch: 101 [step 1/1 (0%)]\tLoss: 0.356226\n",
            "   Test set: Average loss: 0.004949, Accuracy: 582/2000 (29.10%)\n",
            "   Train Epoch: 201 [step 1/1 (0%)]\tLoss: 0.119280\n",
            "   Test set: Average loss: 0.004872, Accuracy: 664/2000 (33.20%)\n",
            "   Train Epoch: 301 [step 1/1 (0%)]\tLoss: 0.066217\n",
            "   Test set: Average loss: 0.004810, Accuracy: 692/2000 (34.60%)\n",
            "   Train Epoch: 401 [step 1/1 (0%)]\tLoss: 0.011078\n",
            "   Test set: Average loss: 0.005294, Accuracy: 587/2000 (29.35%)\n",
            "   Train Epoch: 501 [step 1/1 (0%)]\tLoss: 0.011382\n",
            "   Test set: Average loss: 0.004707, Accuracy: 723/2000 (36.15%)\n",
            "   Train Epoch: 601 [step 1/1 (0%)]\tLoss: 0.003369\n",
            "   Test set: Average loss: 0.004739, Accuracy: 722/2000 (36.10%)\n",
            "   Train Epoch: 700 [step 1/1 (0%)]\tLoss: 0.002384\n",
            "   Test set: Average loss: 0.004751, Accuracy: 710/2000 (35.50%)\n",
            "  Run execution time: train: 800.970 (s) - eval: 0.891 (s)- total: 800.970 (s)\n",
            "  Run# [2/5] - Num Samples For Training 100 - Num Samples For Val 2000\n",
            "   Train Epoch: 1 [step 1/1 (0%)]\tLoss: 1.139166\n",
            "   Test set: Average loss: 0.008429, Accuracy: 232/2000 (11.60%)\n",
            "   Train Epoch: 101 [step 1/1 (0%)]\tLoss: 0.397091\n",
            "   Test set: Average loss: 0.005348, Accuracy: 522/2000 (26.10%)\n",
            "   Train Epoch: 201 [step 1/1 (0%)]\tLoss: 0.112337\n",
            "   Test set: Average loss: 0.005094, Accuracy: 584/2000 (29.20%)\n",
            "   Train Epoch: 301 [step 1/1 (0%)]\tLoss: 0.045031\n",
            "   Test set: Average loss: 0.005159, Accuracy: 619/2000 (30.95%)\n",
            "   Train Epoch: 401 [step 1/1 (0%)]\tLoss: 0.011660\n",
            "   Test set: Average loss: 0.004944, Accuracy: 712/2000 (35.60%)\n",
            "   Train Epoch: 501 [step 1/1 (0%)]\tLoss: 0.009837\n",
            "   Test set: Average loss: 0.004707, Accuracy: 764/2000 (38.20%)\n",
            "   Train Epoch: 601 [step 1/1 (0%)]\tLoss: 0.003438\n",
            "   Test set: Average loss: 0.004750, Accuracy: 748/2000 (37.40%)\n",
            "   Train Epoch: 700 [step 1/1 (0%)]\tLoss: 0.007204\n",
            "   Test set: Average loss: 0.004737, Accuracy: 750/2000 (37.50%)\n",
            "  Run execution time: train: 788.299 (s) - eval: 0.897 (s)- total: 788.299 (s)\n",
            "  Run# [3/5] - Num Samples For Training 100 - Num Samples For Val 2000\n",
            "   Train Epoch: 1 [step 1/1 (0%)]\tLoss: 1.072438\n",
            "   Test set: Average loss: 0.008077, Accuracy: 146/2000 (7.30%)\n",
            "   Train Epoch: 101 [step 1/1 (0%)]\tLoss: 0.430335\n",
            "   Test set: Average loss: 0.004949, Accuracy: 578/2000 (28.90%)\n",
            "   Train Epoch: 201 [step 1/1 (0%)]\tLoss: 0.142497\n",
            "   Test set: Average loss: 0.004709, Accuracy: 702/2000 (35.10%)\n",
            "   Train Epoch: 301 [step 1/1 (0%)]\tLoss: 0.039635\n",
            "   Test set: Average loss: 0.004553, Accuracy: 740/2000 (37.00%)\n",
            "   Train Epoch: 401 [step 1/1 (0%)]\tLoss: 0.011908\n",
            "   Test set: Average loss: 0.005052, Accuracy: 647/2000 (32.35%)\n",
            "   Train Epoch: 501 [step 1/1 (0%)]\tLoss: 0.007805\n",
            "   Test set: Average loss: 0.004845, Accuracy: 682/2000 (34.10%)\n",
            "   Train Epoch: 601 [step 1/1 (0%)]\tLoss: 0.003790\n",
            "   Test set: Average loss: 0.004816, Accuracy: 687/2000 (34.35%)\n",
            "   Train Epoch: 700 [step 1/1 (0%)]\tLoss: 0.002819\n",
            "   Test set: Average loss: 0.004766, Accuracy: 691/2000 (34.55%)\n",
            "  Run execution time: train: 798.546 (s) - eval: 0.913 (s)- total: 798.546 (s)\n",
            "  Run# [4/5] - Num Samples For Training 100 - Num Samples For Val 2000\n",
            "   Train Epoch: 1 [step 1/1 (0%)]\tLoss: 0.958037\n",
            "   Test set: Average loss: 0.006890, Accuracy: 199/2000 (9.95%)\n",
            "   Train Epoch: 101 [step 1/1 (0%)]\tLoss: 0.385195\n",
            "   Test set: Average loss: 0.004865, Accuracy: 583/2000 (29.15%)\n",
            "   Train Epoch: 201 [step 1/1 (0%)]\tLoss: 0.137234\n",
            "   Test set: Average loss: 0.004814, Accuracy: 695/2000 (34.75%)\n",
            "   Train Epoch: 301 [step 1/1 (0%)]\tLoss: 0.039098\n",
            "   Test set: Average loss: 0.004608, Accuracy: 713/2000 (35.65%)\n",
            "   Train Epoch: 401 [step 1/1 (0%)]\tLoss: 0.026571\n",
            "   Test set: Average loss: 0.004655, Accuracy: 722/2000 (36.10%)\n",
            "   Train Epoch: 501 [step 1/1 (0%)]\tLoss: 0.014812\n",
            "   Test set: Average loss: 0.004585, Accuracy: 745/2000 (37.25%)\n",
            "   Train Epoch: 601 [step 1/1 (0%)]\tLoss: 0.003909\n",
            "   Test set: Average loss: 0.004585, Accuracy: 745/2000 (37.25%)\n",
            "   Train Epoch: 700 [step 1/1 (0%)]\tLoss: 0.003205\n",
            "   Test set: Average loss: 0.004598, Accuracy: 755/2000 (37.75%)\n",
            "  Run execution time: train: 809.456 (s) - eval: 0.915 (s)- total: 809.456 (s)\n",
            "  Run# [5/5] - Num Samples For Training 100 - Num Samples For Val 2000\n",
            "   Train Epoch: 1 [step 1/1 (0%)]\tLoss: 1.127742\n",
            "   Test set: Average loss: 0.009247, Accuracy: 200/2000 (10.00%)\n",
            "   Train Epoch: 101 [step 1/1 (0%)]\tLoss: 0.402872\n",
            "   Test set: Average loss: 0.004857, Accuracy: 625/2000 (31.25%)\n",
            "   Train Epoch: 201 [step 1/1 (0%)]\tLoss: 0.177329\n",
            "   Test set: Average loss: 0.005088, Accuracy: 592/2000 (29.60%)\n",
            "   Train Epoch: 301 [step 1/1 (0%)]\tLoss: 0.042042\n",
            "   Test set: Average loss: 0.004588, Accuracy: 726/2000 (36.30%)\n",
            "   Train Epoch: 401 [step 1/1 (0%)]\tLoss: 0.031845\n",
            "   Test set: Average loss: 0.004573, Accuracy: 761/2000 (38.05%)\n",
            "   Train Epoch: 501 [step 1/1 (0%)]\tLoss: 0.020253\n",
            "   Test set: Average loss: 0.004597, Accuracy: 777/2000 (38.85%)\n",
            "   Train Epoch: 601 [step 1/1 (0%)]\tLoss: 0.004851\n",
            "   Test set: Average loss: 0.004527, Accuracy: 780/2000 (39.00%)\n",
            "   Train Epoch: 700 [step 1/1 (0%)]\tLoss: 0.003894\n",
            "   Test set: Average loss: 0.004518, Accuracy: 779/2000 (38.95%)\n",
            "  Run execution time: train: 815.334 (s) - eval: 0.899 (s)- total: 815.334 (s)\n",
            "  Scenario 91/300 - Epochs: 700 - lr: - 0.0005 - dropout: 0.1 - Weight_decay: 0.00016051911333587627 - Grad_clip: 0.004950159553733192\n",
            "  Train time 802.521 +- 9.303 (s) - eval time 0.903 +- 0.010 (s) - total: 802.521 +- 9.303 (s) on Tesla P100-PCIE-16GB\n",
            "  Final acc over 5 instances: 36.85 +- 1.60\n",
            "\n",
            "\n",
            "Current performance summary over 91 completed scenario(s): \n",
            " - Top 10 final average accuracy:\n",
            "   + Scenario: 69 - Final average accuracy: 39.35 +- 1.48%\n",
            "   + Scenario: 59 - Final average accuracy: 38.97 +- 1.24%\n",
            "   + Scenario: 55 - Final average accuracy: 39.06 +- 0.91%\n",
            "   + Scenario: 51 - Final average accuracy: 39.31 +- 0.91%\n",
            "   + Scenario: 1 - Final average accuracy: 38.96 +- 1.23%\n",
            "   + Scenario: 54 - Final average accuracy: 39.06 +- 1.74%\n",
            "   + Scenario: 56 - Final average accuracy: 38.98 +- 1.43%\n",
            "   + Scenario: 60 - Final average accuracy: 39.23 +- 1.38%\n",
            "   + Scenario: 72 - Final average accuracy: 39.06 +- 1.26%\n",
            "   + Scenario: 74 - Final average accuracy: 39.14 +- 1.58%\n",
            " - Top 10 max accuracy:\n",
            "   + Scenario: 57 - run 4 - epoch 670 - Max accuracy: 41.60\n",
            "   + Scenario: 55 - run 6 - epoch 516 - Max accuracy: 41.70\n",
            "   + Scenario: 23 - run 6 - epoch 479 - Max accuracy: 41.85\n",
            "   + Scenario: 23 - run 6 - epoch 478 - Max accuracy: 41.60\n",
            "   + Scenario: 23 - run 6 - epoch 477 - Max accuracy: 41.85\n",
            "   + Scenario: 23 - run 6 - epoch 476 - Max accuracy: 41.75\n",
            "   + Scenario: 23 - run 6 - epoch 459 - Max accuracy: 41.65\n",
            "   + Scenario: 23 - run 6 - epoch 457 - Max accuracy: 41.75\n",
            "   + Scenario: 70 - run 1 - epoch 487 - Max accuracy: 41.65\n",
            "   + Scenario: 72 - run 4 - epoch 514 - Max accuracy: 41.60\n",
            " - Top 10 least final accuracy variation:\n",
            "   + Scenario: 2 - Final average accuracy: 38.41 +- 0.73%\n",
            "   + Scenario: 17 - Final average accuracy: 38.74 +- 0.67%\n",
            "   + Scenario: 19 - Final average accuracy: 38.33 +- 0.50%\n",
            "   + Scenario: 21 - Final average accuracy: 38.67 +- 0.84%\n",
            "   + Scenario: 25 - Final average accuracy: 38.60 +- 0.77%\n",
            "   + Scenario: 34 - Final average accuracy: 35.09 +- 0.69%\n",
            "   + Scenario: 62 - Final average accuracy: 38.93 +- 0.83%\n",
            "   + Scenario: 68 - Final average accuracy: 38.49 +- 0.75%\n",
            "   + Scenario: 76 - Final average accuracy: 38.69 +- 0.73%\n",
            "   + Scenario: 78 - Final average accuracy: 38.63 +- 0.73%\n",
            "\n",
            "Scenario 92/300 - Epochs: 700 - lr: - 0.0005 - dropout: 0.1 - Weight_decay: 0.00016051911333587627 - Grad_clip: 0.015119336467640998\n",
            "  Run# [1/5] - Num Samples For Training 100 - Num Samples For Val 2000\n",
            "   Train Epoch: 1 [step 1/1 (0%)]\tLoss: 1.049838\n",
            "   Test set: Average loss: 0.008718, Accuracy: 191/2000 (9.55%)\n",
            "   Train Epoch: 101 [step 1/1 (0%)]\tLoss: 0.365534\n",
            "   Test set: Average loss: 0.004819, Accuracy: 584/2000 (29.20%)\n",
            "   Train Epoch: 201 [step 1/1 (0%)]\tLoss: 0.131778\n",
            "   Test set: Average loss: 0.005272, Accuracy: 577/2000 (28.85%)\n",
            "   Train Epoch: 301 [step 1/1 (0%)]\tLoss: 0.061894\n",
            "   Test set: Average loss: 0.004796, Accuracy: 675/2000 (33.75%)\n",
            "   Train Epoch: 401 [step 1/1 (0%)]\tLoss: 0.030488\n",
            "   Test set: Average loss: 0.004901, Accuracy: 687/2000 (34.35%)\n",
            "   Train Epoch: 501 [step 1/1 (0%)]\tLoss: 0.007389\n",
            "   Test set: Average loss: 0.004723, Accuracy: 745/2000 (37.25%)\n",
            "   Train Epoch: 601 [step 1/1 (0%)]\tLoss: 0.003235\n",
            "   Test set: Average loss: 0.004619, Accuracy: 751/2000 (37.55%)\n",
            "   Train Epoch: 700 [step 1/1 (0%)]\tLoss: 0.002847\n",
            "   Test set: Average loss: 0.004595, Accuracy: 760/2000 (38.00%)\n",
            "  Run execution time: train: 808.761 (s) - eval: 0.915 (s)- total: 808.761 (s)\n",
            "  Run# [2/5] - Num Samples For Training 100 - Num Samples For Val 2000\n",
            "   Train Epoch: 1 [step 1/1 (0%)]\tLoss: 1.017415\n",
            "   Test set: Average loss: 0.007533, Accuracy: 221/2000 (11.05%)\n",
            "   Train Epoch: 101 [step 1/1 (0%)]\tLoss: 0.410660\n",
            "   Test set: Average loss: 0.004749, Accuracy: 580/2000 (29.00%)\n",
            "   Train Epoch: 201 [step 1/1 (0%)]\tLoss: 0.127936\n",
            "   Test set: Average loss: 0.004851, Accuracy: 674/2000 (33.70%)\n",
            "   Train Epoch: 301 [step 1/1 (0%)]\tLoss: 0.032879\n",
            "   Test set: Average loss: 0.004830, Accuracy: 686/2000 (34.30%)\n",
            "   Train Epoch: 401 [step 1/1 (0%)]\tLoss: 0.023580\n",
            "   Test set: Average loss: 0.004714, Accuracy: 749/2000 (37.45%)\n",
            "   Train Epoch: 501 [step 1/1 (0%)]\tLoss: 0.004537\n",
            "   Test set: Average loss: 0.004648, Accuracy: 759/2000 (37.95%)\n",
            "   Train Epoch: 601 [step 1/1 (0%)]\tLoss: 0.004611\n",
            "   Test set: Average loss: 0.004650, Accuracy: 746/2000 (37.30%)\n",
            "   Train Epoch: 700 [step 1/1 (0%)]\tLoss: 0.002053\n",
            "   Test set: Average loss: 0.004618, Accuracy: 753/2000 (37.65%)\n",
            "  Run execution time: train: 790.065 (s) - eval: 0.895 (s)- total: 790.065 (s)\n",
            "  Run# [3/5] - Num Samples For Training 100 - Num Samples For Val 2000\n",
            "   Train Epoch: 1 [step 1/1 (0%)]\tLoss: 1.104576\n",
            "   Test set: Average loss: 0.008232, Accuracy: 200/2000 (10.00%)\n",
            "   Train Epoch: 101 [step 1/1 (0%)]\tLoss: 0.437056\n",
            "   Test set: Average loss: 0.005120, Accuracy: 541/2000 (27.05%)\n",
            "   Train Epoch: 201 [step 1/1 (0%)]\tLoss: 0.122456\n",
            "   Test set: Average loss: 0.004827, Accuracy: 667/2000 (33.35%)\n",
            "   Train Epoch: 301 [step 1/1 (0%)]\tLoss: 0.028695\n",
            "   Test set: Average loss: 0.004914, Accuracy: 621/2000 (31.05%)\n",
            "   Train Epoch: 401 [step 1/1 (0%)]\tLoss: 0.014926\n",
            "   Test set: Average loss: 0.005067, Accuracy: 616/2000 (30.80%)\n",
            "   Train Epoch: 501 [step 1/1 (0%)]\tLoss: 0.005121\n",
            "   Test set: Average loss: 0.004697, Accuracy: 711/2000 (35.55%)\n",
            "   Train Epoch: 601 [step 1/1 (0%)]\tLoss: 0.007370\n",
            "   Test set: Average loss: 0.004742, Accuracy: 710/2000 (35.50%)\n",
            "   Train Epoch: 700 [step 1/1 (0%)]\tLoss: 0.002105\n",
            "   Test set: Average loss: 0.004663, Accuracy: 714/2000 (35.70%)\n",
            "  Run execution time: train: 786.656 (s) - eval: 0.884 (s)- total: 786.656 (s)\n",
            "  Run# [4/5] - Num Samples For Training 100 - Num Samples For Val 2000\n",
            "   Train Epoch: 1 [step 1/1 (0%)]\tLoss: 0.903690\n",
            "   Test set: Average loss: 0.008600, Accuracy: 197/2000 (9.85%)\n",
            "   Train Epoch: 101 [step 1/1 (0%)]\tLoss: 0.391739\n",
            "   Test set: Average loss: 0.004962, Accuracy: 581/2000 (29.05%)\n",
            "   Train Epoch: 201 [step 1/1 (0%)]\tLoss: 0.160956\n",
            "   Test set: Average loss: 0.004704, Accuracy: 667/2000 (33.35%)\n",
            "   Train Epoch: 301 [step 1/1 (0%)]\tLoss: 0.059110\n",
            "   Test set: Average loss: 0.004767, Accuracy: 680/2000 (34.00%)\n",
            "   Train Epoch: 401 [step 1/1 (0%)]\tLoss: 0.030822\n",
            "   Test set: Average loss: 0.004798, Accuracy: 699/2000 (34.95%)\n",
            "   Train Epoch: 501 [step 1/1 (0%)]\tLoss: 0.007142\n",
            "   Test set: Average loss: 0.004974, Accuracy: 646/2000 (32.30%)\n",
            "   Train Epoch: 601 [step 1/1 (0%)]\tLoss: 0.010624\n",
            "   Test set: Average loss: 0.004717, Accuracy: 730/2000 (36.50%)\n",
            "   Train Epoch: 700 [step 1/1 (0%)]\tLoss: 0.005992\n",
            "   Test set: Average loss: 0.004677, Accuracy: 740/2000 (37.00%)\n",
            "  Run execution time: train: 798.079 (s) - eval: 0.905 (s)- total: 798.079 (s)\n",
            "  Run# [5/5] - Num Samples For Training 100 - Num Samples For Val 2000\n",
            "   Train Epoch: 1 [step 1/1 (0%)]\tLoss: 0.821694\n",
            "   Test set: Average loss: 0.006760, Accuracy: 209/2000 (10.45%)\n",
            "   Train Epoch: 101 [step 1/1 (0%)]\tLoss: 0.406168\n",
            "   Test set: Average loss: 0.004614, Accuracy: 658/2000 (32.90%)\n",
            "   Train Epoch: 201 [step 1/1 (0%)]\tLoss: 0.128781\n",
            "   Test set: Average loss: 0.004714, Accuracy: 690/2000 (34.50%)\n",
            "   Train Epoch: 301 [step 1/1 (0%)]\tLoss: 0.044827\n",
            "   Test set: Average loss: 0.005094, Accuracy: 624/2000 (31.20%)\n",
            "   Train Epoch: 401 [step 1/1 (0%)]\tLoss: 0.022141\n",
            "   Test set: Average loss: 0.004780, Accuracy: 714/2000 (35.70%)\n",
            "   Train Epoch: 501 [step 1/1 (0%)]\tLoss: 0.006398\n",
            "   Test set: Average loss: 0.004610, Accuracy: 754/2000 (37.70%)\n",
            "   Train Epoch: 601 [step 1/1 (0%)]\tLoss: 0.006551\n",
            "   Test set: Average loss: 0.004481, Accuracy: 786/2000 (39.30%)\n",
            "   Train Epoch: 700 [step 1/1 (0%)]\tLoss: 0.007810\n",
            "   Test set: Average loss: 0.004497, Accuracy: 773/2000 (38.65%)\n",
            "  Run execution time: train: 792.857 (s) - eval: 0.890 (s)- total: 792.857 (s)\n",
            "  Scenario 92/300 - Epochs: 700 - lr: - 0.0005 - dropout: 0.1 - Weight_decay: 0.00016051911333587627 - Grad_clip: 0.015119336467640998\n",
            "  Train time 795.283 +- 7.707 (s) - eval time 0.898 +- 0.011 (s) - total: 795.283 +- 7.707 (s) on Tesla P100-PCIE-16GB\n",
            "  Final acc over 5 instances: 37.40 +- 1.00\n",
            "\n",
            "\n",
            "Current performance summary over 92 completed scenario(s): \n",
            " - Top 10 final average accuracy:\n",
            "   + Scenario: 74 - Final average accuracy: 39.14 +- 1.58%\n",
            "   + Scenario: 72 - Final average accuracy: 39.06 +- 1.26%\n",
            "   + Scenario: 60 - Final average accuracy: 39.23 +- 1.38%\n",
            "   + Scenario: 56 - Final average accuracy: 38.98 +- 1.43%\n",
            "   + Scenario: 54 - Final average accuracy: 39.06 +- 1.74%\n",
            "   + Scenario: 1 - Final average accuracy: 38.96 +- 1.23%\n",
            "   + Scenario: 51 - Final average accuracy: 39.31 +- 0.91%\n",
            "   + Scenario: 55 - Final average accuracy: 39.06 +- 0.91%\n",
            "   + Scenario: 59 - Final average accuracy: 38.97 +- 1.24%\n",
            "   + Scenario: 69 - Final average accuracy: 39.35 +- 1.48%\n",
            " - Top 10 max accuracy:\n",
            "   + Scenario: 72 - run 4 - epoch 514 - Max accuracy: 41.60\n",
            "   + Scenario: 70 - run 1 - epoch 487 - Max accuracy: 41.65\n",
            "   + Scenario: 23 - run 6 - epoch 457 - Max accuracy: 41.75\n",
            "   + Scenario: 23 - run 6 - epoch 459 - Max accuracy: 41.65\n",
            "   + Scenario: 23 - run 6 - epoch 476 - Max accuracy: 41.75\n",
            "   + Scenario: 23 - run 6 - epoch 477 - Max accuracy: 41.85\n",
            "   + Scenario: 23 - run 6 - epoch 478 - Max accuracy: 41.60\n",
            "   + Scenario: 23 - run 6 - epoch 479 - Max accuracy: 41.85\n",
            "   + Scenario: 55 - run 6 - epoch 516 - Max accuracy: 41.70\n",
            "   + Scenario: 57 - run 4 - epoch 670 - Max accuracy: 41.60\n",
            " - Top 10 least final accuracy variation:\n",
            "   + Scenario: 2 - Final average accuracy: 38.41 +- 0.73%\n",
            "   + Scenario: 17 - Final average accuracy: 38.74 +- 0.67%\n",
            "   + Scenario: 19 - Final average accuracy: 38.33 +- 0.50%\n",
            "   + Scenario: 21 - Final average accuracy: 38.67 +- 0.84%\n",
            "   + Scenario: 25 - Final average accuracy: 38.60 +- 0.77%\n",
            "   + Scenario: 34 - Final average accuracy: 35.09 +- 0.69%\n",
            "   + Scenario: 62 - Final average accuracy: 38.93 +- 0.83%\n",
            "   + Scenario: 68 - Final average accuracy: 38.49 +- 0.75%\n",
            "   + Scenario: 76 - Final average accuracy: 38.69 +- 0.73%\n",
            "   + Scenario: 78 - Final average accuracy: 38.63 +- 0.73%\n",
            "\n",
            "Scenario 93/300 - Epochs: 700 - lr: - 0.0005 - dropout: 0.1 - Weight_decay: 0.00016051911333587627 - Grad_clip: 0.01567667719550606\n",
            "  Run# [1/5] - Num Samples For Training 100 - Num Samples For Val 2000\n",
            "   Train Epoch: 1 [step 1/1 (0%)]\tLoss: 0.871212\n",
            "   Test set: Average loss: 0.007360, Accuracy: 209/2000 (10.45%)\n",
            "   Train Epoch: 101 [step 1/1 (0%)]\tLoss: 0.350137\n",
            "   Test set: Average loss: 0.004758, Accuracy: 620/2000 (31.00%)\n",
            "   Train Epoch: 201 [step 1/1 (0%)]\tLoss: 0.139469\n",
            "   Test set: Average loss: 0.004885, Accuracy: 700/2000 (35.00%)\n",
            "   Train Epoch: 301 [step 1/1 (0%)]\tLoss: 0.047655\n",
            "   Test set: Average loss: 0.004778, Accuracy: 706/2000 (35.30%)\n",
            "   Train Epoch: 401 [step 1/1 (0%)]\tLoss: 0.038821\n",
            "   Test set: Average loss: 0.004883, Accuracy: 686/2000 (34.30%)\n",
            "   Train Epoch: 501 [step 1/1 (0%)]\tLoss: 0.006179\n",
            "   Test set: Average loss: 0.004825, Accuracy: 714/2000 (35.70%)\n",
            "   Train Epoch: 601 [step 1/1 (0%)]\tLoss: 0.004128\n",
            "   Test set: Average loss: 0.004722, Accuracy: 725/2000 (36.25%)\n",
            "   Train Epoch: 700 [step 1/1 (0%)]\tLoss: 0.003213\n",
            "   Test set: Average loss: 0.004710, Accuracy: 737/2000 (36.85%)\n",
            "  Run execution time: train: 809.455 (s) - eval: 0.917 (s)- total: 809.455 (s)\n",
            "  Run# [2/5] - Num Samples For Training 100 - Num Samples For Val 2000\n",
            "   Train Epoch: 1 [step 1/1 (0%)]\tLoss: 0.993034\n",
            "   Test set: Average loss: 0.008005, Accuracy: 200/2000 (10.00%)\n",
            "   Train Epoch: 101 [step 1/1 (0%)]\tLoss: 0.415621\n",
            "   Test set: Average loss: 0.005012, Accuracy: 544/2000 (27.20%)\n",
            "   Train Epoch: 201 [step 1/1 (0%)]\tLoss: 0.133210\n",
            "   Test set: Average loss: 0.004746, Accuracy: 691/2000 (34.55%)\n",
            "   Train Epoch: 301 [step 1/1 (0%)]\tLoss: 0.041699\n",
            "   Test set: Average loss: 0.004780, Accuracy: 717/2000 (35.85%)\n",
            "   Train Epoch: 401 [step 1/1 (0%)]\tLoss: 0.018624\n",
            "   Test set: Average loss: 0.004859, Accuracy: 684/2000 (34.20%)\n",
            "   Train Epoch: 501 [step 1/1 (0%)]\tLoss: 0.008544\n",
            "   Test set: Average loss: 0.004827, Accuracy: 704/2000 (35.20%)\n",
            "   Train Epoch: 601 [step 1/1 (0%)]\tLoss: 0.007276\n",
            "   Test set: Average loss: 0.004573, Accuracy: 768/2000 (38.40%)\n",
            "   Train Epoch: 700 [step 1/1 (0%)]\tLoss: 0.003452\n",
            "   Test set: Average loss: 0.004597, Accuracy: 762/2000 (38.10%)\n",
            "  Run execution time: train: 819.968 (s) - eval: 0.918 (s)- total: 819.968 (s)\n",
            "  Run# [3/5] - Num Samples For Training 100 - Num Samples For Val 2000\n",
            "   Train Epoch: 1 [step 1/1 (0%)]\tLoss: 1.074780\n",
            "   Test set: Average loss: 0.008019, Accuracy: 231/2000 (11.55%)\n",
            "   Train Epoch: 101 [step 1/1 (0%)]\tLoss: 0.403910\n",
            "   Test set: Average loss: 0.005061, Accuracy: 563/2000 (28.15%)\n",
            "   Train Epoch: 201 [step 1/1 (0%)]\tLoss: 0.138794\n",
            "   Test set: Average loss: 0.004963, Accuracy: 639/2000 (31.95%)\n",
            "   Train Epoch: 301 [step 1/1 (0%)]\tLoss: 0.057407\n",
            "   Test set: Average loss: 0.005146, Accuracy: 594/2000 (29.70%)\n",
            "   Train Epoch: 401 [step 1/1 (0%)]\tLoss: 0.019601\n",
            "   Test set: Average loss: 0.005043, Accuracy: 656/2000 (32.80%)\n",
            "   Train Epoch: 501 [step 1/1 (0%)]\tLoss: 0.004547\n",
            "   Test set: Average loss: 0.004881, Accuracy: 674/2000 (33.70%)\n",
            "   Train Epoch: 601 [step 1/1 (0%)]\tLoss: 0.003592\n",
            "   Test set: Average loss: 0.004724, Accuracy: 710/2000 (35.50%)\n",
            "   Train Epoch: 700 [step 1/1 (0%)]\tLoss: 0.002631\n",
            "   Test set: Average loss: 0.004752, Accuracy: 698/2000 (34.90%)\n",
            "  Run execution time: train: 819.444 (s) - eval: 0.899 (s)- total: 819.444 (s)\n",
            "  Run# [4/5] - Num Samples For Training 100 - Num Samples For Val 2000\n",
            "   Train Epoch: 1 [step 1/1 (0%)]\tLoss: 1.102136\n",
            "   Test set: Average loss: 0.008229, Accuracy: 200/2000 (10.00%)\n",
            "   Train Epoch: 101 [step 1/1 (0%)]\tLoss: 0.396939\n",
            "   Test set: Average loss: 0.004664, Accuracy: 636/2000 (31.80%)\n",
            "   Train Epoch: 201 [step 1/1 (0%)]\tLoss: 0.125882\n",
            "   Test set: Average loss: 0.004837, Accuracy: 630/2000 (31.50%)\n",
            "   Train Epoch: 301 [step 1/1 (0%)]\tLoss: 0.041684\n",
            "   Test set: Average loss: 0.005274, Accuracy: 540/2000 (27.00%)\n",
            "   Train Epoch: 401 [step 1/1 (0%)]\tLoss: 0.028680\n",
            "   Test set: Average loss: 0.004649, Accuracy: 715/2000 (35.75%)\n",
            "   Train Epoch: 501 [step 1/1 (0%)]\tLoss: 0.013001\n",
            "   Test set: Average loss: 0.004787, Accuracy: 721/2000 (36.05%)\n",
            "   Train Epoch: 601 [step 1/1 (0%)]\tLoss: 0.003462\n",
            "   Test set: Average loss: 0.004472, Accuracy: 784/2000 (39.20%)\n",
            "   Train Epoch: 700 [step 1/1 (0%)]\tLoss: 0.005501\n",
            "   Test set: Average loss: 0.004463, Accuracy: 794/2000 (39.70%)\n",
            "  Run execution time: train: 805.240 (s) - eval: 0.909 (s)- total: 805.240 (s)\n",
            "  Run# [5/5] - Num Samples For Training 100 - Num Samples For Val 2000\n",
            "   Train Epoch: 1 [step 1/1 (0%)]\tLoss: 1.049922\n",
            "   Test set: Average loss: 0.007234, Accuracy: 206/2000 (10.30%)\n",
            "   Train Epoch: 101 [step 1/1 (0%)]\tLoss: 0.392783\n",
            "   Test set: Average loss: 0.004908, Accuracy: 601/2000 (30.05%)\n",
            "   Train Epoch: 201 [step 1/1 (0%)]\tLoss: 0.170802\n",
            "   Test set: Average loss: 0.005065, Accuracy: 669/2000 (33.45%)\n",
            "   Train Epoch: 301 [step 1/1 (0%)]\tLoss: 0.061225\n",
            "   Test set: Average loss: 0.004836, Accuracy: 663/2000 (33.15%)\n",
            "   Train Epoch: 401 [step 1/1 (0%)]\tLoss: 0.031697\n",
            "   Test set: Average loss: 0.004470, Accuracy: 773/2000 (38.65%)\n",
            "   Train Epoch: 501 [step 1/1 (0%)]\tLoss: 0.010203\n",
            "   Test set: Average loss: 0.004517, Accuracy: 775/2000 (38.75%)\n",
            "   Train Epoch: 601 [step 1/1 (0%)]\tLoss: 0.005508\n",
            "   Test set: Average loss: 0.004507, Accuracy: 786/2000 (39.30%)\n",
            "   Train Epoch: 700 [step 1/1 (0%)]\tLoss: 0.005677\n",
            "   Test set: Average loss: 0.004485, Accuracy: 795/2000 (39.75%)\n",
            "  Run execution time: train: 804.747 (s) - eval: 0.911 (s)- total: 804.747 (s)\n",
            "  Scenario 93/300 - Epochs: 700 - lr: - 0.0005 - dropout: 0.1 - Weight_decay: 0.00016051911333587627 - Grad_clip: 0.01567667719550606\n",
            "  Train time 811.771 +- 6.685 (s) - eval time 0.911 +- 0.007 (s) - total: 811.771 +- 6.685 (s) on Tesla P100-PCIE-16GB\n",
            "  Final acc over 5 instances: 37.86 +- 1.83\n",
            "\n",
            "\n",
            "Current performance summary over 93 completed scenario(s): \n",
            " - Top 10 final average accuracy:\n",
            "   + Scenario: 69 - Final average accuracy: 39.35 +- 1.48%\n",
            "   + Scenario: 59 - Final average accuracy: 38.97 +- 1.24%\n",
            "   + Scenario: 55 - Final average accuracy: 39.06 +- 0.91%\n",
            "   + Scenario: 51 - Final average accuracy: 39.31 +- 0.91%\n",
            "   + Scenario: 1 - Final average accuracy: 38.96 +- 1.23%\n",
            "   + Scenario: 54 - Final average accuracy: 39.06 +- 1.74%\n",
            "   + Scenario: 56 - Final average accuracy: 38.98 +- 1.43%\n",
            "   + Scenario: 60 - Final average accuracy: 39.23 +- 1.38%\n",
            "   + Scenario: 72 - Final average accuracy: 39.06 +- 1.26%\n",
            "   + Scenario: 74 - Final average accuracy: 39.14 +- 1.58%\n",
            " - Top 10 max accuracy:\n",
            "   + Scenario: 57 - run 4 - epoch 670 - Max accuracy: 41.60\n",
            "   + Scenario: 55 - run 6 - epoch 516 - Max accuracy: 41.70\n",
            "   + Scenario: 23 - run 6 - epoch 479 - Max accuracy: 41.85\n",
            "   + Scenario: 23 - run 6 - epoch 478 - Max accuracy: 41.60\n",
            "   + Scenario: 23 - run 6 - epoch 477 - Max accuracy: 41.85\n",
            "   + Scenario: 23 - run 6 - epoch 476 - Max accuracy: 41.75\n",
            "   + Scenario: 23 - run 6 - epoch 459 - Max accuracy: 41.65\n",
            "   + Scenario: 23 - run 6 - epoch 457 - Max accuracy: 41.75\n",
            "   + Scenario: 70 - run 1 - epoch 487 - Max accuracy: 41.65\n",
            "   + Scenario: 72 - run 4 - epoch 514 - Max accuracy: 41.60\n",
            " - Top 10 least final accuracy variation:\n",
            "   + Scenario: 2 - Final average accuracy: 38.41 +- 0.73%\n",
            "   + Scenario: 17 - Final average accuracy: 38.74 +- 0.67%\n",
            "   + Scenario: 19 - Final average accuracy: 38.33 +- 0.50%\n",
            "   + Scenario: 21 - Final average accuracy: 38.67 +- 0.84%\n",
            "   + Scenario: 25 - Final average accuracy: 38.60 +- 0.77%\n",
            "   + Scenario: 34 - Final average accuracy: 35.09 +- 0.69%\n",
            "   + Scenario: 62 - Final average accuracy: 38.93 +- 0.83%\n",
            "   + Scenario: 68 - Final average accuracy: 38.49 +- 0.75%\n",
            "   + Scenario: 76 - Final average accuracy: 38.69 +- 0.73%\n",
            "   + Scenario: 78 - Final average accuracy: 38.63 +- 0.73%\n",
            "\n",
            "Scenario 94/300 - Epochs: 700 - lr: - 0.0005 - dropout: 0.1 - Weight_decay: 0.00016051911333587627 - Grad_clip: 0.02576638574613588\n",
            "  Run# [1/5] - Num Samples For Training 100 - Num Samples For Val 2000\n",
            "   Train Epoch: 1 [step 1/1 (0%)]\tLoss: 1.027899\n",
            "   Test set: Average loss: 0.007638, Accuracy: 200/2000 (10.00%)\n",
            "   Train Epoch: 101 [step 1/1 (0%)]\tLoss: 0.381497\n",
            "   Test set: Average loss: 0.005072, Accuracy: 545/2000 (27.25%)\n",
            "   Train Epoch: 201 [step 1/1 (0%)]\tLoss: 0.127783\n",
            "   Test set: Average loss: 0.004840, Accuracy: 652/2000 (32.60%)\n",
            "   Train Epoch: 301 [step 1/1 (0%)]\tLoss: 0.044446\n",
            "   Test set: Average loss: 0.005214, Accuracy: 626/2000 (31.30%)\n",
            "   Train Epoch: 401 [step 1/1 (0%)]\tLoss: 0.030888\n",
            "   Test set: Average loss: 0.005192, Accuracy: 631/2000 (31.55%)\n",
            "   Train Epoch: 501 [step 1/1 (0%)]\tLoss: 0.013347\n",
            "   Test set: Average loss: 0.004639, Accuracy: 764/2000 (38.20%)\n",
            "   Train Epoch: 601 [step 1/1 (0%)]\tLoss: 0.003219\n",
            "   Test set: Average loss: 0.004580, Accuracy: 767/2000 (38.35%)\n",
            "   Train Epoch: 700 [step 1/1 (0%)]\tLoss: 0.004455\n",
            "   Test set: Average loss: 0.004616, Accuracy: 764/2000 (38.20%)\n",
            "  Run execution time: train: 803.461 (s) - eval: 0.895 (s)- total: 803.461 (s)\n",
            "  Run# [2/5] - Num Samples For Training 100 - Num Samples For Val 2000\n",
            "   Train Epoch: 1 [step 1/1 (0%)]\tLoss: 0.986832\n",
            "   Test set: Average loss: 0.007036, Accuracy: 200/2000 (10.00%)\n",
            "   Train Epoch: 101 [step 1/1 (0%)]\tLoss: 0.424546\n",
            "   Test set: Average loss: 0.005567, Accuracy: 473/2000 (23.65%)\n",
            "   Train Epoch: 201 [step 1/1 (0%)]\tLoss: 0.117060\n",
            "   Test set: Average loss: 0.005110, Accuracy: 620/2000 (31.00%)\n",
            "   Train Epoch: 301 [step 1/1 (0%)]\tLoss: 0.045358\n",
            "   Test set: Average loss: 0.004879, Accuracy: 684/2000 (34.20%)\n",
            "   Train Epoch: 401 [step 1/1 (0%)]\tLoss: 0.021243\n",
            "   Test set: Average loss: 0.004871, Accuracy: 688/2000 (34.40%)\n",
            "   Train Epoch: 501 [step 1/1 (0%)]\tLoss: 0.009675\n",
            "   Test set: Average loss: 0.004930, Accuracy: 676/2000 (33.80%)\n",
            "   Train Epoch: 601 [step 1/1 (0%)]\tLoss: 0.005172\n",
            "   Test set: Average loss: 0.004763, Accuracy: 722/2000 (36.10%)\n",
            "   Train Epoch: 700 [step 1/1 (0%)]\tLoss: 0.002691\n",
            "   Test set: Average loss: 0.004750, Accuracy: 727/2000 (36.35%)\n",
            "  Run execution time: train: 795.666 (s) - eval: 0.891 (s)- total: 795.666 (s)\n",
            "  Run# [3/5] - Num Samples For Training 100 - Num Samples For Val 2000\n",
            "   Train Epoch: 1 [step 1/1 (0%)]\tLoss: 1.040118\n",
            "   Test set: Average loss: 0.008722, Accuracy: 200/2000 (10.00%)\n",
            "   Train Epoch: 101 [step 1/1 (0%)]\tLoss: 0.433993\n",
            "   Test set: Average loss: 0.004948, Accuracy: 557/2000 (27.85%)\n",
            "   Train Epoch: 201 [step 1/1 (0%)]\tLoss: 0.104671\n",
            "   Test set: Average loss: 0.004691, Accuracy: 698/2000 (34.90%)\n",
            "   Train Epoch: 301 [step 1/1 (0%)]\tLoss: 0.037413\n",
            "   Test set: Average loss: 0.004863, Accuracy: 707/2000 (35.35%)\n",
            "   Train Epoch: 401 [step 1/1 (0%)]\tLoss: 0.024291\n",
            "   Test set: Average loss: 0.004797, Accuracy: 702/2000 (35.10%)\n",
            "   Train Epoch: 501 [step 1/1 (0%)]\tLoss: 0.011669\n",
            "   Test set: Average loss: 0.004832, Accuracy: 685/2000 (34.25%)\n",
            "   Train Epoch: 601 [step 1/1 (0%)]\tLoss: 0.006254\n",
            "   Test set: Average loss: 0.004720, Accuracy: 716/2000 (35.80%)\n",
            "   Train Epoch: 700 [step 1/1 (0%)]\tLoss: 0.002470\n",
            "   Test set: Average loss: 0.004718, Accuracy: 706/2000 (35.30%)\n",
            "  Run execution time: train: 794.519 (s) - eval: 0.901 (s)- total: 794.519 (s)\n",
            "  Run# [4/5] - Num Samples For Training 100 - Num Samples For Val 2000\n",
            "   Train Epoch: 1 [step 1/1 (0%)]\tLoss: 0.974580\n",
            "   Test set: Average loss: 0.006856, Accuracy: 210/2000 (10.50%)\n",
            "   Train Epoch: 101 [step 1/1 (0%)]\tLoss: 0.403164\n",
            "   Test set: Average loss: 0.004685, Accuracy: 584/2000 (29.20%)\n",
            "   Train Epoch: 201 [step 1/1 (0%)]\tLoss: 0.149309\n",
            "   Test set: Average loss: 0.004640, Accuracy: 713/2000 (35.65%)\n",
            "   Train Epoch: 301 [step 1/1 (0%)]\tLoss: 0.049971\n",
            "   Test set: Average loss: 0.004775, Accuracy: 679/2000 (33.95%)\n",
            "   Train Epoch: 401 [step 1/1 (0%)]\tLoss: 0.019326\n",
            "   Test set: Average loss: 0.004697, Accuracy: 708/2000 (35.40%)\n",
            "   Train Epoch: 501 [step 1/1 (0%)]\tLoss: 0.014129\n",
            "   Test set: Average loss: 0.004693, Accuracy: 734/2000 (36.70%)\n",
            "   Train Epoch: 601 [step 1/1 (0%)]\tLoss: 0.003231\n",
            "   Test set: Average loss: 0.004573, Accuracy: 755/2000 (37.75%)\n",
            "   Train Epoch: 700 [step 1/1 (0%)]\tLoss: 0.004828\n",
            "   Test set: Average loss: 0.004511, Accuracy: 760/2000 (38.00%)\n",
            "  Run execution time: train: 795.938 (s) - eval: 0.923 (s)- total: 795.938 (s)\n",
            "  Run# [5/5] - Num Samples For Training 100 - Num Samples For Val 2000\n",
            "   Train Epoch: 1 [step 1/1 (0%)]\tLoss: 1.206652\n",
            "   Test set: Average loss: 0.009448, Accuracy: 230/2000 (11.50%)\n",
            "   Train Epoch: 101 [step 1/1 (0%)]\tLoss: 0.419872\n",
            "   Test set: Average loss: 0.004826, Accuracy: 609/2000 (30.45%)\n",
            "   Train Epoch: 201 [step 1/1 (0%)]\tLoss: 0.131106\n",
            "   Test set: Average loss: 0.004680, Accuracy: 720/2000 (36.00%)\n",
            "   Train Epoch: 301 [step 1/1 (0%)]\tLoss: 0.051616\n",
            "   Test set: Average loss: 0.004847, Accuracy: 680/2000 (34.00%)\n",
            "   Train Epoch: 401 [step 1/1 (0%)]\tLoss: 0.030128\n",
            "   Test set: Average loss: 0.004700, Accuracy: 706/2000 (35.30%)\n",
            "   Train Epoch: 501 [step 1/1 (0%)]\tLoss: 0.006961\n",
            "   Test set: Average loss: 0.004505, Accuracy: 785/2000 (39.25%)\n",
            "   Train Epoch: 601 [step 1/1 (0%)]\tLoss: 0.002596\n",
            "   Test set: Average loss: 0.004527, Accuracy: 758/2000 (37.90%)\n",
            "   Train Epoch: 700 [step 1/1 (0%)]\tLoss: 0.003060\n",
            "   Test set: Average loss: 0.004496, Accuracy: 775/2000 (38.75%)\n",
            "  Run execution time: train: 808.830 (s) - eval: 0.924 (s)- total: 808.830 (s)\n",
            "  Scenario 94/300 - Epochs: 700 - lr: - 0.0005 - dropout: 0.1 - Weight_decay: 0.00016051911333587627 - Grad_clip: 0.02576638574613588\n",
            "  Train time 799.683 +- 5.564 (s) - eval time 0.907 +- 0.014 (s) - total: 799.683 +- 5.564 (s) on Tesla P100-PCIE-16GB\n",
            "  Final acc over 5 instances: 37.32 +- 1.29\n",
            "\n",
            "\n",
            "Current performance summary over 94 completed scenario(s): \n",
            " - Top 10 final average accuracy:\n",
            "   + Scenario: 74 - Final average accuracy: 39.14 +- 1.58%\n",
            "   + Scenario: 72 - Final average accuracy: 39.06 +- 1.26%\n",
            "   + Scenario: 60 - Final average accuracy: 39.23 +- 1.38%\n",
            "   + Scenario: 56 - Final average accuracy: 38.98 +- 1.43%\n",
            "   + Scenario: 54 - Final average accuracy: 39.06 +- 1.74%\n",
            "   + Scenario: 1 - Final average accuracy: 38.96 +- 1.23%\n",
            "   + Scenario: 51 - Final average accuracy: 39.31 +- 0.91%\n",
            "   + Scenario: 55 - Final average accuracy: 39.06 +- 0.91%\n",
            "   + Scenario: 59 - Final average accuracy: 38.97 +- 1.24%\n",
            "   + Scenario: 69 - Final average accuracy: 39.35 +- 1.48%\n",
            " - Top 10 max accuracy:\n",
            "   + Scenario: 72 - run 4 - epoch 514 - Max accuracy: 41.60\n",
            "   + Scenario: 70 - run 1 - epoch 487 - Max accuracy: 41.65\n",
            "   + Scenario: 23 - run 6 - epoch 457 - Max accuracy: 41.75\n",
            "   + Scenario: 23 - run 6 - epoch 459 - Max accuracy: 41.65\n",
            "   + Scenario: 23 - run 6 - epoch 476 - Max accuracy: 41.75\n",
            "   + Scenario: 23 - run 6 - epoch 477 - Max accuracy: 41.85\n",
            "   + Scenario: 23 - run 6 - epoch 478 - Max accuracy: 41.60\n",
            "   + Scenario: 23 - run 6 - epoch 479 - Max accuracy: 41.85\n",
            "   + Scenario: 55 - run 6 - epoch 516 - Max accuracy: 41.70\n",
            "   + Scenario: 57 - run 4 - epoch 670 - Max accuracy: 41.60\n",
            " - Top 10 least final accuracy variation:\n",
            "   + Scenario: 2 - Final average accuracy: 38.41 +- 0.73%\n",
            "   + Scenario: 17 - Final average accuracy: 38.74 +- 0.67%\n",
            "   + Scenario: 19 - Final average accuracy: 38.33 +- 0.50%\n",
            "   + Scenario: 21 - Final average accuracy: 38.67 +- 0.84%\n",
            "   + Scenario: 25 - Final average accuracy: 38.60 +- 0.77%\n",
            "   + Scenario: 34 - Final average accuracy: 35.09 +- 0.69%\n",
            "   + Scenario: 62 - Final average accuracy: 38.93 +- 0.83%\n",
            "   + Scenario: 68 - Final average accuracy: 38.49 +- 0.75%\n",
            "   + Scenario: 76 - Final average accuracy: 38.69 +- 0.73%\n",
            "   + Scenario: 78 - Final average accuracy: 38.63 +- 0.73%\n",
            "\n",
            "Scenario 95/300 - Epochs: 700 - lr: - 0.0005 - dropout: 0.1 - Weight_decay: 0.00016051911333587627 - Grad_clip: 0.07257005721594274\n",
            "  Run# [1/5] - Num Samples For Training 100 - Num Samples For Val 2000\n",
            "   Train Epoch: 1 [step 1/1 (0%)]\tLoss: 1.095875\n",
            "   Test set: Average loss: 0.008749, Accuracy: 174/2000 (8.70%)\n",
            "   Train Epoch: 101 [step 1/1 (0%)]\tLoss: 0.395465\n",
            "   Test set: Average loss: 0.004803, Accuracy: 598/2000 (29.90%)\n",
            "   Train Epoch: 201 [step 1/1 (0%)]\tLoss: 0.112056\n",
            "   Test set: Average loss: 0.004626, Accuracy: 711/2000 (35.55%)\n",
            "   Train Epoch: 301 [step 1/1 (0%)]\tLoss: 0.034251\n",
            "   Test set: Average loss: 0.005151, Accuracy: 640/2000 (32.00%)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}